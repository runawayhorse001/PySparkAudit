%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,12pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{2}

\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{dsfont}
\def\Z{\mathbb{Z}}
\def\R{\mathbb{R}}
\def\bX{\mathbf{X}}
\def\X{\mathbf{X}}
\def\By{\mathbf{y}}
\def\Bbeta{\boldsymbol{\beta}}
\def\bU{\mathbf{U}}
\def\bV{\mathbf{V}}
\def\V1{\mathds{1}}
\def\hU{\mathbf{\hat{U}}}
\def\hS{\mathbf{\hat{\Sigma}}}
\def\hV{\mathbf{\hat{V}}}
\def\E{\mathbf{E}}
\def\F{\mathbf{F}}
\def\x{\mathbf{x}}
\def\h{\mathbf{h}}
\def\v{\mathbf{v}}
\def\nv{\mathbf{v^{{f -}}}}
\def\nh{\mathbf{h^{{f -}}}}
\def\s{\mathbf{s}}
\def\b{\mathbf{b}}
\def\c{\mathbf{c}}
\def\W{\mathbf{W}}
\def\C{\mathbf{C}}
\def\P{\mathbf{P}}
\def\T{{\bf \mathcal T}}
\def\B{{\bf \mathcal B}}
\def\euler{\ e^{i\pi} + 1 = 0}


\title{PySparkAudit: PySpark Data Audit}
\date{July 03, 2019}
\release{}
\author{Wenqiang Feng and Yiming Xu}
\newcommand{\sphinxlogo}{\sphinxincludegraphics{logo.png}\par}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\maketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}\phantomsection\label{\detokenize{index:index}}\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{logo}.png}
\end{figure}
\end{quote}

Welcome to our \sphinxstylestrong{PySparkAudit: PySpark Data Audit Library API}! The PDF version can be downloaded from \sphinxhref{PySparkAudit.pdf}{HERE}.

You can install the \sphinxcode{\sphinxupquote{PySparkAudit}} from {[}PyPI{]}(\sphinxurl{https://pypi.org/project/PySparkAudit}):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
pip install PySparkAudit
\end{sphinxVerbatim}




\chapter{Preface}
\label{\detokenize{preface:preface}}\label{\detokenize{preface:id1}}\label{\detokenize{preface::doc}}
\begin{sphinxadmonition}{note}{Chinese proverb}

Good tools are prerequisite to the successful execution of a job. \textendash{} old Chinese proverb
\end{sphinxadmonition}


\section{About}
\label{\detokenize{preface:about}}

\subsection{About this API}
\label{\detokenize{preface:about-this-api}}
This document is the \sphinxcode{\sphinxupquote{API}} book for our \sphinxstylestrong{PySparkAudit}: PySpark Data Audit Library \sphinxcite{reference:pysparkaudit} API. The PDF version can be downloaded from \sphinxhref{PySparkAudit.pdf}{HERE}. \sphinxstylestrong{You may download and distribute it. Please be aware, however, that the note contains typos as well as inaccurate or incorrect description.}

The \sphinxcode{\sphinxupquote{API}} assumes that the reader has a preliminary knowledge of \sphinxcode{\sphinxupquote{python}} programing and \sphinxcode{\sphinxupquote{Linux}}. And this document is generated automatically by using \sphinxhref{http://sphinx.pocoo.org}{sphinx}.

The python version \sphinxstylestrong{PyAudit}: Python Data Audit Library API can be found at \sphinxcite{reference:pyaudit}.


\subsection{About the author}
\label{\detokenize{preface:about-the-author}}\begin{itemize}
\item {} 
\sphinxstylestrong{Wenqiang Feng}
\begin{itemize}
\item {} 
Data Scientist and PhD in Mathematics

\item {} 
University of Tennessee at Knoxville

\item {} 
Webpage: \sphinxurl{http://web.utk.edu/~wfeng1/}

\item {} 
Email: \sphinxhref{mailto:von198@gmail.com}{von198@gmail.com}

\end{itemize}

\item {} 
\sphinxstylestrong{Yiming Xu}
\begin{itemize}
\item {} 
Data Scientist and Master of Data Science

\item {} 
Harvard University

\item {} 
Email:  \sphinxhref{mailto:yimingxu@g.harvard.edu}{yimingxu@g.harvard.edu}

\end{itemize}

\item {} 
\sphinxstylestrong{Biography}

Wenqiang Feng is Data Scientist within DST’s Applied Analytics Group. Dr. Feng’s responsibilities include providing DST clients with access to cutting-edge skills and technologies, including Big Data analytic solutions, advanced analytic and data enhancement techniques and modeling.

Dr. Feng has deep analytic expertise in data mining, analytic systems, machine learning algorithms, business intelligence, and applying Big Data tools to strategically solve industry problems in a cross-functional business. Before joining DST, Dr. Feng was an IMA Data Science Fellow at The Institute for Mathematics and its Applications (IMA) at the University of Minnesota. While there, he helped startup companies make marketing decisions based on deep predictive analytics.

Dr. Feng graduated from University of Tennessee, Knoxville, with Ph.D. in Computational Mathematics and Master’s degree in Statistics. He also holds Master’s degree in Computational Mathematics from Missouri University of Science and Technology (MST) and Master’s degree in Applied Mathematics from the University of Science and Technology of China (USTC).

\item {} 
\sphinxstylestrong{Declaration}

The work of Wenqiang Feng was supported by the IMA, while working at IMA. However, any opinion, finding, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the IMA, UTK, DST and Harvard University.

\end{itemize}


\section{Acknowledgement}
\label{\detokenize{preface:acknowledgement}}
At here, Wenqiang Feng would like to thank \sphinxstylestrong{Weiyu Wang} at Missouri University of Science and Technology and
\sphinxstylestrong{Jiangtao (Lotto) Xie} at Purdue University for the unit testing and valuable disscussion.


\section{Feedback and suggestions}
\label{\detokenize{preface:feedback-and-suggestions}}
Your comments and suggestions are highly appreciated. I am more than happy to receive
corrections, suggestions or feedbacks through email (Wenqiang Feng: \sphinxhref{mailto:von198@gmail.com}{von198@gmail.com} and Yiming Xu: \sphinxhref{mailto:yimingxu@g.harvard.edu}{yimingxu@g.harvard.edu}) for improvements.


\chapter{How to Install}
\label{\detokenize{install:how-to-install}}\label{\detokenize{install:install}}\label{\detokenize{install::doc}}

\section{Install with \sphinxstyleliteralintitle{\sphinxupquote{pip}}}
\label{\detokenize{install:install-with-pip}}
You can install the \sphinxcode{\sphinxupquote{PySparkAudit}} from {[}PyPI{]}(\sphinxurl{https://pypi.org/project/PySparkAudit}):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
pip install PySparkAudit
\end{sphinxVerbatim}


\section{Install from Repo}
\label{\detokenize{install:install-from-repo}}

\subsection{Clone the Repository}
\label{\detokenize{install:clone-the-repository}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git clone https://github.com/runawayhorse001/PySparkAudit.git
\end{sphinxVerbatim}


\subsection{Install}
\label{\detokenize{install:id1}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{cd} PySparkAudit
pip install \PYGZhy{}r requirements.txt
python setup.py install
\end{sphinxVerbatim}


\section{Uninstall}
\label{\detokenize{install:uninstall}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
pip uninstall statspy
\end{sphinxVerbatim}


\section{Test}
\label{\detokenize{install:test}}

\subsection{Run test code}
\label{\detokenize{install:run-test-code}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{cd} PySparkAudit/test
python test.py
\end{sphinxVerbatim}

\sphinxcode{\sphinxupquote{test.py}}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pyspark.sql} \PYG{k+kn}{import} \PYG{n}{SparkSession}

\PYG{n}{spark} \PYG{o}{=} \PYG{n}{SparkSession} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{builder} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{appName}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Python Spark regression example}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{spark.some.config.option}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some\PYGZhy{}value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{getOrCreate}\PYG{p}{(}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} from PySparkAudit import dtypes\PYGZus{}class, hist\PYGZus{}plot, bar\PYGZus{}plot, freq\PYGZus{}items,feature\PYGZus{}len}
\PYG{c+c1}{\PYGZsh{} from PySparkAudit import dataset\PYGZus{}summary, rates, trend\PYGZus{}plot}

\PYG{c+c1}{\PYGZsh{} path = \PYGZsq{}/home/feng/Desktop\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} import PySpark Audit function}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{auditing}

\PYG{c+c1}{\PYGZsh{} load dataset}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{csv}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Heart.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{encoding}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{UTF\PYGZhy{}8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{comment}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{header}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{inferSchema}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} auditing in one function }
\PYG{k}{print}\PYG{p}{(}\PYG{n}{auditing}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Audited Results}
\label{\detokenize{install:audited-results}}\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_folder}.png}
\end{figure}
\end{quote}


\chapter{PySpark Data Audit Functions}
\label{\detokenize{basics:pyspark-data-audit-functions}}\label{\detokenize{basics:basics}}\label{\detokenize{basics::doc}}

\section{Basic Functions}
\label{\detokenize{basics:basic-functions}}

\subsection{mkdir}
\label{\detokenize{basics:mkdir}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{mkdir}}}{\emph{path}}{}
Make a new directory. if it’s exist, keep the old files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{path}} \textendash{} the directory path

\end{description}\end{quote}

\end{fulllineitems}



\subsection{mkdir\_clean}
\label{\detokenize{basics:mkdir-clean}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{mkdir\_clean}}}{\emph{path}}{}
Make a new directory. if it’s exist, remove the old files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{path}} \textendash{} the directory path

\end{description}\end{quote}

\end{fulllineitems}



\subsection{df\_merge}
\label{\detokenize{basics:df-merge}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{df\_merge}}}{\emph{dfs}, \emph{key}, \emph{how='left'}}{}
Merge multiple pandas data frames with same key.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{dfs}} \textendash{} name list of the data frames

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{key}} \textendash{} key for join

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{how}} \textendash{} method for join, the default value is left

\end{itemize}

\item[{Returns}] \leavevmode
merged data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{data\_types}
\label{\detokenize{basics:data-types}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{data\_types}}}{\emph{df\_in}, \emph{tracking=False}}{}
Generate the data types of the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
data types pandas data frame

\end{description}\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{createDataFrame}\PYG{p}{(}\PYG{p}{[}
\PYG{g+go}{                    (\PYGZsq{}Joe\PYGZsq{}, 67, \PYGZsq{}F\PYGZsq{}, 7000, \PYGZsq{}asymptomatic\PYGZsq{}, 286.1, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Henry\PYGZsq{}, 67, \PYGZsq{}M\PYGZsq{}, 8000, \PYGZsq{}asymptomatic\PYGZsq{}, 229.2, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}29\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Sam\PYGZsq{}, 37,  \PYGZsq{}F\PYGZsq{}, 6000, \PYGZsq{}nonanginal\PYGZsq{}, 250.3, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}30\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Max\PYGZsq{}, 56, \PYGZsq{}M\PYGZsq{}, 9000, \PYGZsq{}nontypical\PYGZsq{}, 236.4, \PYGZsq{}2019\PYGZhy{}5\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Mat\PYGZsq{}, 56, \PYGZsq{}F\PYGZsq{}, 9000, \PYGZsq{}asymptomatic\PYGZsq{}, 254.5, \PYGZsq{}2019\PYGZhy{}4\PYGZhy{}28\PYGZsq{})],}
\PYG{g+go}{                    [\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}, \PYGZsq{}CreatDate\PYGZsq{}]}
\PYG{g+go}{                   )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{test}\PYG{o}{.}\PYG{n}{withColumn}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CreatDate}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{F}\PYG{o}{.}\PYG{n}{col}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CreatDate}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{cast}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{timestamp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k}{import} \PYG{n}{data\PYGZus{}types}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{data\PYGZus{}types}\PYG{p}{(}\PYG{n}{test}\PYG{p}{)}
\PYG{g+go}{     feature     dtypes}
\PYG{g+go}{0       Name     string}
\PYG{g+go}{1        Age     bigint}
\PYG{g+go}{2        Sex     string}
\PYG{g+go}{3     Salary     bigint}
\PYG{g+go}{4  ChestPain     string}
\PYG{g+go}{5       Chol     double}
\PYG{g+go}{6  CreatDate  timestamp}
\end{sphinxVerbatim}

\end{fulllineitems}



\subsection{dtypes\_class}
\label{\detokenize{basics:dtypes-class}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{dtypes\_class}}}{\emph{df\_in}}{}
Generate the data type categories: numerical, categorical, date and unsupported category.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item[{Returns}] \leavevmode
data type categories

\end{description}\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{createDataFrame}\PYG{p}{(}\PYG{p}{[}
\PYG{g+go}{                    (\PYGZsq{}Joe\PYGZsq{}, 67, \PYGZsq{}F\PYGZsq{}, 7000, \PYGZsq{}asymptomatic\PYGZsq{}, 286.1, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Henry\PYGZsq{}, 67, \PYGZsq{}M\PYGZsq{}, 8000, \PYGZsq{}asymptomatic\PYGZsq{}, 229.2, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}29\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Sam\PYGZsq{}, 37,  \PYGZsq{}F\PYGZsq{}, 6000, \PYGZsq{}nonanginal\PYGZsq{}, 250.3, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}30\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Max\PYGZsq{}, 56, \PYGZsq{}M\PYGZsq{}, 9000, \PYGZsq{}nontypical\PYGZsq{}, 236.4, \PYGZsq{}2019\PYGZhy{}5\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Mat\PYGZsq{}, 56, \PYGZsq{}F\PYGZsq{}, 9000, \PYGZsq{}asymptomatic\PYGZsq{}, 254.5, \PYGZsq{}2019\PYGZhy{}4\PYGZhy{}28\PYGZsq{})],}
\PYG{g+go}{                    [\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}, \PYGZsq{}CreatDate\PYGZsq{}]}
\PYG{g+go}{                   )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{test}\PYG{o}{.}\PYG{n}{withColumn}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CreatDate}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{F}\PYG{o}{.}\PYG{n}{col}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CreatDate}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{cast}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{timestamp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k}{import} \PYG{n}{dtypes\PYGZus{}class}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{dtypes\PYGZus{}class}\PYG{p}{(}\PYG{n}{test}\PYG{p}{)}
\PYG{g+go}{(     feature       DataType}
\PYG{g+go}{0       Name     StringType}
\PYG{g+go}{1        Age       LongType}
\PYG{g+go}{2        Sex     StringType}
\PYG{g+go}{3    Salary       LongType}
\PYG{g+go}{4  ChestPain     StringType}
\PYG{g+go}{5       Chol     DoubleType}
\PYG{g+go}{6  CreatDate  TimestampType,}
\PYG{g+go}{[\PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}],}
\PYG{g+go}{[\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}],}
\PYG{g+go}{[\PYGZsq{}CreatDate\PYGZsq{}], [])}
\end{sphinxVerbatim}

\end{fulllineitems}



\subsection{counts}
\label{\detokenize{basics:counts}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{counts}}}{\emph{df\_in}, \emph{tracking=False}}{}
Generate the row counts and not null rows and distinct counts for each feature.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the counts in pandas data frame

\end{description}\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{createDataFrame}\PYG{p}{(}\PYG{p}{[}
\PYG{g+go}{                    (\PYGZsq{}Joe\PYGZsq{}, None, \PYGZsq{}F\PYGZsq{}, 70000, \PYGZsq{}asymptomatic\PYGZsq{}, 286.1, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Henry\PYGZsq{}, 67, \PYGZsq{}M\PYGZsq{}, 80000, \PYGZsq{}asymptomatic\PYGZsq{}, 229.2, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}29\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Sam\PYGZsq{}, 37,  \PYGZsq{}F\PYGZsq{}, 60000, \PYGZsq{}nonanginal\PYGZsq{}, 250.3, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}30\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Max\PYGZsq{}, 56, \PYGZsq{}  \PYGZsq{}, 90000, None, 236.4, \PYGZsq{}2019\PYGZhy{}5\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Mat\PYGZsq{}, 56, \PYGZsq{}F\PYGZsq{}, None, \PYGZsq{}asymptomatic\PYGZsq{}, 254.5, \PYGZsq{}2019\PYGZhy{}4\PYGZhy{}28\PYGZsq{})],}
\PYG{g+go}{                    [\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}, \PYGZsq{}CreatDate\PYGZsq{}]}
\PYG{g+go}{                   )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{test}\PYG{o}{.}\PYG{n}{withColumn}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CreatDate}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{F}\PYG{o}{.}\PYG{n}{col}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CreatDate}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{cast}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{timestamp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k}{import} \PYG{n}{counts}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{counts}\PYG{p}{(}\PYG{n}{test}\PYG{p}{)}
\PYG{g+go}{     feature  row\PYGZus{}count  notnull\PYGZus{}count  distinct\PYGZus{}count}
\PYG{g+go}{0       Name          5              5               5}
\PYG{g+go}{1        Age          5              4               3}
\PYG{g+go}{2        Sex          5              5               3}
\PYG{g+go}{3     Salary          5              4               4}
\PYG{g+go}{4  ChestPain          5              4               2}
\PYG{g+go}{5       Chol          5              5               5}
\PYG{g+go}{6  CreatDate          5              5               5}
\end{sphinxVerbatim}

\end{fulllineitems}



\subsection{describe}
\label{\detokenize{basics:describe}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{describe}}}{\emph{df\_in}, \emph{columns=None}, \emph{tracking=False}}{}
Generate the simple data frame description using \(.describe()\) function in pyspark.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the description in pandas data frame

\end{description}\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{createDataFrame}\PYG{p}{(}\PYG{p}{[}
\PYG{g+go}{                (\PYGZsq{}Joe\PYGZsq{}, 67, \PYGZsq{}F\PYGZsq{}, 7000, \PYGZsq{}asymptomatic\PYGZsq{}, 286.1, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                (\PYGZsq{}Henry\PYGZsq{}, 67, \PYGZsq{}M\PYGZsq{}, 8000, \PYGZsq{}asymptomatic\PYGZsq{}, 229.2, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}29\PYGZsq{}),}
\PYG{g+go}{                (\PYGZsq{}Sam\PYGZsq{}, 37,  \PYGZsq{}F\PYGZsq{}, 6000, \PYGZsq{}nonanginal\PYGZsq{}, 250.3, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}30\PYGZsq{}),}
\PYG{g+go}{                (\PYGZsq{}Max\PYGZsq{}, 56, \PYGZsq{}M\PYGZsq{}, 9000, \PYGZsq{}nontypical\PYGZsq{}, 236.4, \PYGZsq{}2019\PYGZhy{}5\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                (\PYGZsq{}Mat\PYGZsq{}, 56, \PYGZsq{}F\PYGZsq{}, 9000, \PYGZsq{}asymptomatic\PYGZsq{}, 254.5, \PYGZsq{}2019\PYGZhy{}4\PYGZhy{}28\PYGZsq{})],}
\PYG{g+go}{                [\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}, \PYGZsq{}CreatDate\PYGZsq{}]}
\PYG{g+go}{               )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{test}\PYG{o}{.}\PYG{n}{withColumn}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CreatDate}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{F}\PYG{o}{.}\PYG{n}{col}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CreatDate}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{cast}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{timestamp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k}{import} \PYG{n}{describe}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{describe}\PYG{p}{(}\PYG{n}{test}\PYG{p}{)}
\PYG{g+go}{summary   count     mean     ...               min         max}
\PYG{g+go}{feature                      ...}
\PYG{g+go}{Name          5     None     ...             Henry         Sam}
\PYG{g+go}{Age           5     56.6     ...                37          67}
\PYG{g+go}{Sex           5     None     ...                 F           M}
\PYG{g+go}{Salary        5  78000.0     ...             60000       90000}
\PYG{g+go}{ChestPain     5     None     ...      asymptomatic  nontypical}
\PYG{g+go}{Chol          5    251.3     ...             229.2       286.1}
\PYG{g+go}{CreatDate     5     None     ...         2019\PYGZhy{}4\PYGZhy{}28   2019\PYGZhy{}6\PYGZhy{}30}
\end{sphinxVerbatim}

{[}7 rows x 5 columns{]}

\end{fulllineitems}



\subsection{percentiles}
\label{\detokenize{basics:percentiles}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{percentiles}}}{\emph{df\_in}, \emph{deciles=False}, \emph{tracking=False}}{}
Generate the percentiles for rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{deciles}} \textendash{} the flag for generate the deciles

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
percentiles in pandas data frame

\end{description}\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{createDataFrame}\PYG{p}{(}\PYG{p}{[}
\PYG{g+go}{                    (\PYGZsq{}Joe\PYGZsq{}, 67, \PYGZsq{}F\PYGZsq{}, 7000, \PYGZsq{}asymptomatic\PYGZsq{}, 286.1, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Henry\PYGZsq{}, 67, \PYGZsq{}M\PYGZsq{}, 8000, \PYGZsq{}asymptomatic\PYGZsq{}, 229.2, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}29\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Sam\PYGZsq{}, 37,  \PYGZsq{}F\PYGZsq{}, 6000, \PYGZsq{}nonanginal\PYGZsq{}, 250.3, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}30\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Max\PYGZsq{}, 56, \PYGZsq{}M\PYGZsq{}, 9000, \PYGZsq{}nontypical\PYGZsq{}, 236.4, \PYGZsq{}2019\PYGZhy{}5\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Mat\PYGZsq{}, 56, \PYGZsq{}F\PYGZsq{}, 9000, \PYGZsq{}asymptomatic\PYGZsq{}, 254.5, \PYGZsq{}2019\PYGZhy{}4\PYGZhy{}28\PYGZsq{})],}
\PYG{g+go}{                    [\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}, \PYGZsq{}CreatDate\PYGZsq{}]}
\PYG{g+go}{                   )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k}{import} \PYG{n}{percentiles}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{percentiles}\PYG{p}{(}\PYG{n}{test}\PYG{p}{)}
\PYG{g+go}{   feature       Q1      Med       Q3}
\PYG{g+go}{0      Age     56.0     67.0     67.0}
\PYG{g+go}{1   Salary  80000.0  90000.0  90000.0}
\PYG{g+go}{2     Chol    250.3    254.5    286.1}
\end{sphinxVerbatim}

\end{fulllineitems}



\subsection{feature\_len}
\label{\detokenize{basics:feature-len}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{feature\_len}}}{\emph{df\_in}, \emph{tracking=False}}{}
Generate feature length statistical results for each feature in the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the feature length statistical results in pandas data frame

\end{description}\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{createDataFrame}\PYG{p}{(}\PYG{p}{[}
\PYG{g+go}{                    (\PYGZsq{}Joe\PYGZsq{}, 67, \PYGZsq{}F\PYGZsq{}, 7000, \PYGZsq{}asymptomatic\PYGZsq{}, 286.1, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Henry\PYGZsq{}, 67, \PYGZsq{}M\PYGZsq{}, 8000, \PYGZsq{}asymptomatic\PYGZsq{}, 229.2, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}29\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Sam\PYGZsq{}, 37,  \PYGZsq{}F\PYGZsq{}, 6000, \PYGZsq{}nonanginal\PYGZsq{}, 250.3, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}30\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Max\PYGZsq{}, 56, \PYGZsq{}M\PYGZsq{}, 9000, \PYGZsq{}nontypical\PYGZsq{}, 236.4, \PYGZsq{}2019\PYGZhy{}5\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Mat\PYGZsq{}, 56, \PYGZsq{}F\PYGZsq{}, 9000, \PYGZsq{}asymptomatic\PYGZsq{}, 254.5, \PYGZsq{}2019\PYGZhy{}4\PYGZhy{}28\PYGZsq{})],}
\PYG{g+go}{                    [\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}, \PYGZsq{}CreatDate\PYGZsq{}]}
\PYG{g+go}{                   )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k}{import} \PYG{n}{feature\PYGZus{}len}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{feature\PYGZus{}len}\PYG{p}{(}\PYG{n}{test}\PYG{p}{)}
\PYG{g+go}{     feature  min\PYGZus{}length  avg\PYGZus{}length  max\PYGZus{}length}
\PYG{g+go}{0       Name         3.0         3.4         5.0}
\PYG{g+go}{1        Age         2.0         2.0         2.0}
\PYG{g+go}{2        Sex         1.0         1.0         1.0}
\PYG{g+go}{3     Salary         5.0         5.0         5.0}
\PYG{g+go}{4  ChestPain        10.0        11.2        12.0}
\PYG{g+go}{5       Chol         5.0         5.0         5.0}
\PYG{g+go}{6  CreatDate         9.0         9.0         9.0}
\end{sphinxVerbatim}

\end{fulllineitems}



\subsection{freq\_items}
\label{\detokenize{basics:freq-items}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{freq\_items}}}{\emph{df\_in}, \emph{top\_n=5}, \emph{tracking=False}}{}
Generate the top\_n frequent items in for each feature in the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent item

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode


\end{description}\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{createDataFrame}\PYG{p}{(}\PYG{p}{[}
\PYG{g+go}{                    (\PYGZsq{}Joe\PYGZsq{}, 67, \PYGZsq{}F\PYGZsq{}, 7000, \PYGZsq{}asymptomatic\PYGZsq{}, 286.1, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Henry\PYGZsq{}, 67, \PYGZsq{}M\PYGZsq{}, 8000, \PYGZsq{}asymptomatic\PYGZsq{}, 229.2, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}29\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Sam\PYGZsq{}, 37,  \PYGZsq{}F\PYGZsq{}, 6000, \PYGZsq{}nonanginal\PYGZsq{}, 250.3, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}30\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Max\PYGZsq{}, 56, \PYGZsq{}M\PYGZsq{}, 9000, \PYGZsq{}nontypical\PYGZsq{}, 236.4, \PYGZsq{}2019\PYGZhy{}5\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Mat\PYGZsq{}, 56, \PYGZsq{}F\PYGZsq{}, 9000, \PYGZsq{}asymptomatic\PYGZsq{}, 254.5, \PYGZsq{}2019\PYGZhy{}4\PYGZhy{}28\PYGZsq{})],}
\PYG{g+go}{                    [\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}, \PYGZsq{}CreatDate\PYGZsq{}]}
\PYG{g+go}{                   )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k}{import} \PYG{n}{freq\PYGZus{}items}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{freq\PYGZus{}items}\PYG{p}{(}\PYG{n}{test}\PYG{p}{)}
\PYG{g+go}{     feature                            freq\PYGZus{}items[value, freq]}
\PYG{g+go}{0       Name  [[Joe, 1], [Mat, 1], [Henry, 1], [Sam, 1], [Ma...}
\PYG{g+go}{1        Age                        [[67, 2], [56, 2], [37, 1]]}
\PYG{g+go}{2        Sex                                   [[F, 3], [M, 2]]}
\PYG{g+go}{3    Salary   [[90000, 2], [70000, 1], [80000, 1], [60000, 1]]}
\PYG{g+go}{4  ChestPain  [[asymptomatic, 3], [nontypical, 1], [nonangin...}
\PYG{g+go}{5       Chol  [[286.1, 1], [250.3, 1], [229.2, 1], [236.4, 1...}
\PYG{g+go}{6  CreatDate  [[2019\PYGZhy{}6\PYGZhy{}30, 1], [2019\PYGZhy{}5\PYGZhy{}28, 1], [2019\PYGZhy{}4\PYGZhy{}28, 1...}
\end{sphinxVerbatim}

\end{fulllineitems}



\subsection{rates}
\label{\detokenize{basics:rates}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{rates}}}{\emph{df\_in}, \emph{columns=None}, \emph{numeric=True}, \emph{tracking=False}}{}
Generate the null, empty, negative, zero and  positive value rates and feature variance for
each feature in the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{numeric}} \textendash{} the flag for numerical rdd data frame, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the null, empty, negative, zero and  positive value rates and feature variance
in pandas data frame

\end{description}\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{createDataFrame}\PYG{p}{(}\PYG{p}{[}
\PYG{g+go}{                    (\PYGZsq{}Joe\PYGZsq{}, 67, \PYGZsq{}F\PYGZsq{}, 7000, \PYGZsq{}asymptomatic\PYGZsq{}, 286.1, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Henry\PYGZsq{}, 67, \PYGZsq{}M\PYGZsq{}, 8000, \PYGZsq{}asymptomatic\PYGZsq{}, 229.2, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}29\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Sam\PYGZsq{}, 37,  \PYGZsq{}F\PYGZsq{}, 6000, \PYGZsq{}nonanginal\PYGZsq{}, 250.3, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}30\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Max\PYGZsq{}, 56, \PYGZsq{}M\PYGZsq{}, 9000, \PYGZsq{}nontypical\PYGZsq{}, 236.4, \PYGZsq{}2019\PYGZhy{}5\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Mat\PYGZsq{}, 56, \PYGZsq{}F\PYGZsq{}, 9000, \PYGZsq{}asymptomatic\PYGZsq{}, 254.5, \PYGZsq{}2019\PYGZhy{}4\PYGZhy{}28\PYGZsq{})],}
\PYG{g+go}{                    [\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}, \PYGZsq{}CreatDate\PYGZsq{}]}
\PYG{g+go}{                   )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k}{import} \PYG{n}{rates}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{rates}\PYG{p}{(}\PYG{n}{test}\PYG{p}{)}
\PYG{g+go}{     feature  feature\PYGZus{}variance    ...     rate\PYGZus{}zero  rate\PYGZus{}pos}
\PYG{g+go}{0        Age               0.6    ...           0.0       1.0}
\PYG{g+go}{1     Salary               0.8    ...           0.0       1.0}
\PYG{g+go}{2       Chol               1.0    ...           0.0       1.0}
\PYG{g+go}{3       Name               1.0    ...           0.0       0.0}
\PYG{g+go}{4        Sex               0.4    ...           0.0       0.0}
\PYG{g+go}{5  ChestPain               0.6    ...           0.0       0.0}
\PYG{g+go}{6  CreatDate               1.0    ...           0.0       0.0}
\end{sphinxVerbatim}

{[}7 rows x 7 columns{]}

\end{fulllineitems}



\subsection{corr\_matrix}
\label{\detokenize{basics:corr-matrix}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{corr\_matrix}}}{\emph{df\_in}, \emph{method='pearson'}, \emph{output\_dir=None}, \emph{rotation=True}, \emph{display=False}, \emph{tracking=False}}{}
Generate the correlation matrix and heat map plot for rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{method}} \textendash{} the method which applied to calculate the correlation matrix: pearson or spearman.
the default value is pearson

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the correlation matrix in pandas data frame

\end{description}\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{test} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{createDataFrame}\PYG{p}{(}\PYG{p}{[}
\PYG{g+go}{                    (\PYGZsq{}Joe\PYGZsq{}, 67, \PYGZsq{}F\PYGZsq{}, 7000, \PYGZsq{}asymptomatic\PYGZsq{}, 286.1, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Henry\PYGZsq{}, 67, \PYGZsq{}M\PYGZsq{}, 8000, \PYGZsq{}asymptomatic\PYGZsq{}, 229.2, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}29\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Sam\PYGZsq{}, 37,  \PYGZsq{}F\PYGZsq{}, 6000, \PYGZsq{}nonanginal\PYGZsq{}, 250.3, \PYGZsq{}2019\PYGZhy{}6\PYGZhy{}30\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Max\PYGZsq{}, 56, \PYGZsq{}M\PYGZsq{}, 9000, \PYGZsq{}nontypical\PYGZsq{}, 236.4, \PYGZsq{}2019\PYGZhy{}5\PYGZhy{}28\PYGZsq{}),}
\PYG{g+go}{                    (\PYGZsq{}Mat\PYGZsq{}, 56, \PYGZsq{}F\PYGZsq{}, 9000, \PYGZsq{}asymptomatic\PYGZsq{}, 254.5, \PYGZsq{}2019\PYGZhy{}4\PYGZhy{}28\PYGZsq{})],}
\PYG{g+go}{                    [\PYGZsq{}Name\PYGZsq{}, \PYGZsq{}Age\PYGZsq{}, \PYGZsq{}Sex\PYGZsq{}, \PYGZsq{}Salary\PYGZsq{}, \PYGZsq{}ChestPain\PYGZsq{}, \PYGZsq{}Chol\PYGZsq{}, \PYGZsq{}CreatDate\PYGZsq{}]}
\PYG{g+go}{                   )}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k}{import} \PYG{n}{corr\PYGZus{}matrix}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{corr\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{test}\PYG{p}{)}
\PYG{g+go}{================================================================}
\PYG{g+go}{The correlation matrix plot Corr.png was located at:}
\PYG{g+go}{/home/feng/Audited}
\PYG{g+go}{              Age   Salary      Chol}
\PYG{g+go}{Age      1.000000  0.431663  0.147226}
\PYG{g+go}{Salary   0.431663  1.000000 \PYGZhy{}0.388171}
\PYG{g+go}{Chol     0.147226 \PYGZhy{}0.388171  1.000000}
\end{sphinxVerbatim}

\end{fulllineitems}



\section{Plot Functions}
\label{\detokenize{basics:plot-functions}}

\subsection{hist\_plot}
\label{\detokenize{basics:hist-plot}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{hist\_plot}}}{\emph{df\_in}, \emph{bins=50}, \emph{output\_dir=None}, \emph{sample\_size=None}, \emph{display=False}, \emph{tracking=False}}{}
Histogram plot for the numerical features in the rdd data frame. \sphinxstylestrong{This part is super time and
memory consuming.} If the data size is larger than 10,000, the histograms will be saved in .pdf
format. Otherwise, the histograms will be saved in .png format in hist folder.

If your time and memory are limited, you can use sample\_size to generate the subset of the data
frame to generate the histograms.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{bins}} \textendash{} the number of bins for generate the bar plots

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sample\_size}} \textendash{} the size for generate the subset from the rdd data frame, the
default value none

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{bar\_plot}
\label{\detokenize{basics:bar-plot}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{bar\_plot}}}{\emph{df\_in}, \emph{top\_n=20}, \emph{rotation=True}, \emph{output\_dir=None}, \emph{display=False}, \emph{tracking=False}}{}
Bar plot for the categorical features in the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent feature to show in the bar plot

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{trend\_plot}
\label{\detokenize{basics:trend-plot}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{trend\_plot}}}{\emph{df\_in}, \emph{types='day'}, \emph{d\_time=None}, \emph{rotation=True}, \emph{output\_dir=None}, \emph{display=False}, \emph{tracking=False}}{}
Trend plot for the aggregated time series data if the rdd data frame has date features and numerical features.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{types}} \textendash{} the types for time feature aggregation: day, month, year, the default value is day

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{d\_time}} \textendash{} the specific feature name of the date feature, the default value
is the first date feature in the rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\section{Summary Functions}
\label{\detokenize{basics:summary-functions}}

\subsection{dataset\_summary}
\label{\detokenize{basics:dataset-summary}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{dataset\_summary}}}{\emph{df\_in}, \emph{tracking=False}}{}
The data set basics summary.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
data set summary in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{numeric\_summary}
\label{\detokenize{basics:numeric-summary}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{numeric\_summary}}}{\emph{df\_in}, \emph{columns=None}, \emph{deciles=False}, \emph{top\_n=5}, \emph{tracking=False}}{}
The auditing function for numerical rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{deciles}} \textendash{} the flag for generate the deciles

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent item

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the audited results for the numerical features in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{category\_summary}
\label{\detokenize{basics:category-summary}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{category\_summary}}}{\emph{df\_in}, \emph{columns=None}, \emph{top\_n=5}, \emph{tracking=False}}{}
The auditing function for categorical rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent item

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the audited results for the categorical features in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\section{Auditing Function}
\label{\detokenize{basics:auditing-function}}

\subsection{auditing}
\label{\detokenize{basics:auditing}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{auditing}}}{\emph{df\_in}, \emph{writer=None}, \emph{columns=None}, \emph{deciles=False}, \emph{top\_freq\_item=5}, \emph{bins=50}, \emph{top\_cat\_item=20}, \emph{method='pearson'}, \emph{output\_dir=None}, \emph{types='day'}, \emph{d\_time=None}, \emph{rotation=True}, \emph{sample\_size=None}, \emph{display=False}, \emph{tracking=False}}{}
The wrapper of auditing functions.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{writer}} \textendash{} the writer for excel output

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{deciles}} \textendash{} the flag for generate the deciles

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_freq\_item}} \textendash{} the number of the most frequent item

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{bins}} \textendash{} the number of bins for generate the bar plots

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_cat\_item}} \textendash{} the number of the most frequent feature to show in the bar plot

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{method}} \textendash{} the method which applied to calculate the correlation matrix: pearson or spearman.
the default value is pearson

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{types}} \textendash{} the types for time feature aggregation: day, month, year, the default value is day

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{d\_time}} \textendash{} the specific feature name of the date feature, the default value
is the first date feature in the rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sample\_size}} \textendash{} the size for generate the subset from the rdd data frame, the
default value none

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the all audited results in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\section{Plotting Function}
\label{\detokenize{basics:plotting-function}}

\subsection{fig\_plots}
\label{\detokenize{basics:fig-plots}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{fig\_plots}}}{\emph{df\_in}, \emph{output\_dir=None}, \emph{bins=50}, \emph{top\_n=20}, \emph{types='day'}, \emph{d\_time=None}, \emph{rotation=True}, \emph{sample\_size=None}, \emph{display=False}, \emph{tracking=False}}{}
The wrapper for the plot functions.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{bins}} \textendash{} the number of bins for generate the bar plots

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent feature to show in the bar plot

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{types}} \textendash{} the types for time feature aggregation: day, month, year, the default value is day

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{d\_time}} \textendash{} the specific feature name of the date feature, the default value
is the first date feature in the rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sample\_size}} \textendash{} the size for generate the subset from the rdd data frame, the
default value none

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\chapter{Auditing Demos}
\label{\detokenize{demo:auditing-demos}}\label{\detokenize{demo:demo}}\label{\detokenize{demo::doc}}
The following demos are designed to show how to use \sphinxcode{\sphinxupquote{PySparkAudit}} to aduit rdd \sphinxcode{\sphinxupquote{DataFrame}}.


\section{Auditing function by function}
\label{\detokenize{demo:auditing-function-by-function}}
If you just need a piece of the audit result, you can call the corresponding function to generate it.
There are 9 basic auditing functions, 3 figure plot functions and 3 summary functions in the PySparkAudit library.

syntax

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
from PySparkAudit import *
\end{sphinxVerbatim}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Basic Functions:
\begin{enumerate}
\def\theenumii{\alph{enumii}}
\def\labelenumii{\theenumii .}
\makeatletter\def\p@enumiii{\p@enumii \theenumii .}\makeatother
\item {} 
data\_types: \sphinxcode{\sphinxupquote{PySparkAudit.data\_types}}

\item {} 
dtypes\_class: \sphinxcode{\sphinxupquote{PySparkAudit.dtypes\_class}}

\item {} 
dtypes\_class: \sphinxcode{\sphinxupquote{PySparkAudit.counts}}

\item {} 
dtypes\_class: \sphinxcode{\sphinxupquote{PySparkAudit.describe}}

\item {} 
dtypes\_class: \sphinxcode{\sphinxupquote{PySparkAudit.percentiles}}

\item {} 
dtypes\_class: \sphinxcode{\sphinxupquote{PySparkAudit.feature\_len}}

\item {} 
dtypes\_class: \sphinxcode{\sphinxupquote{PySparkAudit.freq\_items}}

\item {} 
dtypes\_class: \sphinxcode{\sphinxupquote{PySparkAudit.rates}}

\item {} 
dtypes\_class: \sphinxcode{\sphinxupquote{PySparkAudit.corr\_matrix}}

\end{enumerate}

\item {} 
Plot Functions:
\begin{enumerate}
\def\theenumii{\alph{enumii}}
\def\labelenumii{\theenumii .}
\makeatletter\def\p@enumiii{\p@enumii \theenumii .}\makeatother
\item {} 
hist\_plot: \sphinxcode{\sphinxupquote{PySparkAudit.hist\_plot}}

\item {} 
bar\_plot: \sphinxcode{\sphinxupquote{PySparkAudit.bar\_plot}}

\item {} 
trend\_plot: \sphinxcode{\sphinxupquote{PySparkAudit.trend\_plot}}

\end{enumerate}

\item {} 
Summary Functions
\begin{enumerate}
\def\theenumii{\alph{enumii}}
\def\labelenumii{\theenumii .}
\makeatletter\def\p@enumiii{\p@enumii \theenumii .}\makeatother
\item {} 
dataset\_summary: \sphinxcode{\sphinxupquote{PySparkAudit.dataset\_summary}}

\item {} 
numeric\_summary: \sphinxcode{\sphinxupquote{PySparkAudit.numeric\_summary}}

\item {} 
category\_summary: \sphinxcode{\sphinxupquote{PySparkAudit.category\_summary}}

\end{enumerate}

\end{enumerate}

For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pyspark.sql} \PYG{k+kn}{import} \PYG{n}{SparkSession}

\PYG{n}{spark} \PYG{o}{=} \PYG{n}{SparkSession} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{builder} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{appName}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Python Spark regression example}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{spark.some.config.option}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some\PYGZhy{}value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{getOrCreate}\PYG{p}{(}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} import PySpark Audit functions}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{data\PYGZus{}types}\PYG{p}{,} \PYG{n}{hist\PYGZus{}plot}\PYG{p}{,} \PYG{n}{bar\PYGZus{}plot}\PYG{p}{,} \PYG{n}{freq\PYGZus{}items}\PYG{p}{,}\PYG{n}{feature\PYGZus{}len}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{dataset\PYGZus{}summary}\PYG{p}{,} \PYG{n}{rates}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{trend\PYGZus{}plot}\PYG{p}{,} \PYG{n}{auditing}

\PYG{c+c1}{\PYGZsh{} load dataset}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{csv}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Heart.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{encoding}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{UTF\PYGZhy{}8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{comment}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{header}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{inferSchema}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} audit function by function}

\PYG{c+c1}{\PYGZsh{} data types}
\PYG{k}{print}\PYG{p}{(}\PYG{n}{data\PYGZus{}types}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} check frequent items}
\PYG{k}{print}\PYG{p}{(}\PYG{n}{freq\PYGZus{}items}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} bar plot for categorical features}
\PYG{n}{bar\PYGZus{}plot}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}  \PYG{n}{display}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\end{sphinxVerbatim}

Result:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
      feature  dtypes
\PYG{l+m}{0}         Age     int
\PYG{l+m}{1}         Sex     int
\PYG{l+m}{2}   ChestPain  string
\PYG{l+m}{3}      RestBP     int
\PYG{l+m}{4}        Chol     int
\PYG{l+m}{5}         Fbs     int
\PYG{l+m}{6}     RestECG     int
\PYG{l+m}{7}       MaxHR     int
\PYG{l+m}{8}       ExAng     int
\PYG{l+m}{9}     Oldpeak  double
\PYG{l+m}{10}      Slope     int
\PYG{l+m}{11}         Ca  string
\PYG{l+m}{12}       Thal  string
\PYG{l+m}{13}        AHD  string
      feature                            freq\PYGZus{}items\PYG{o}{[}value, freq\PYG{o}{]}
\PYG{l+m}{0}         Age  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{58}, \PYG{l+m}{19}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{57}, \PYG{l+m}{17}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{54}, \PYG{l+m}{16}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{59}, \PYG{l+m}{14}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{52}, ...
\PYG{l+m}{1}         Sex                                \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{206}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{97}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{2}   ChestPain  \PYG{o}{[}\PYG{o}{[}asymptomatic, \PYG{l+m}{144}\PYG{o}{]}, \PYG{o}{[}nonanginal, \PYG{l+m}{86}\PYG{o}{]}, \PYG{o}{[}nonty...
\PYG{l+m}{3}      RestBP  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{120}, \PYG{l+m}{37}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{130}, \PYG{l+m}{36}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{140}, \PYG{l+m}{32}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{110}, \PYG{l+m}{19}\PYG{o}{]}, \PYG{o}{[}...
\PYG{l+m}{4}        Chol  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{197}, \PYG{l+m}{6}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{234}, \PYG{l+m}{6}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{204}, \PYG{l+m}{6}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{254}, \PYG{l+m}{5}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{212},...
\PYG{l+m}{5}         Fbs                                \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{258}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{45}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{6}     RestECG                       \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{151}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{2}, \PYG{l+m}{148}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{4}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{7}       MaxHR  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{162}, \PYG{l+m}{11}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{163}, \PYG{l+m}{9}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{160}, \PYG{l+m}{9}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{152}, \PYG{l+m}{8}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{132}...
\PYG{l+m}{8}       ExAng                                \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{204}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{99}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{9}     Oldpeak  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}.0, \PYG{l+m}{99}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}.2, \PYG{l+m}{17}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{0}.6, \PYG{l+m}{14}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}.0, \PYG{l+m}{14}\PYG{o}{]}, \PYG{o}{[}...
\PYG{l+m}{10}      Slope                      \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{142}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{2}, \PYG{l+m}{140}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{3}, \PYG{l+m}{21}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{11}         Ca     \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{176}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{65}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{2}, \PYG{l+m}{38}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{3}, \PYG{l+m}{20}\PYG{o}{]}, \PYG{o}{[}NA, \PYG{l+m}{4}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{12}       Thal  \PYG{o}{[}\PYG{o}{[}normal, \PYG{l+m}{166}\PYG{o}{]}, \PYG{o}{[}reversable, \PYG{l+m}{117}\PYG{o}{]}, \PYG{o}{[}fixed, \PYG{l+m}{18}\PYG{o}{]}...
\PYG{l+m}{13}        AHD                            \PYG{o}{[}\PYG{o}{[}No, \PYG{l+m}{164}\PYG{o}{]}, \PYG{o}{[}Yes, \PYG{l+m}{139}\PYG{o}{]}\PYG{o}{]}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The Bar plot Bar\PYGZus{}plots.pdf was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited

Process finished with \PYG{n+nb}{exit} code \PYG{l+m}{0}
\end{sphinxVerbatim}

and
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{bars}.png}
\end{figure}
\end{quote}


\section{Auditing in one function}
\label{\detokenize{demo:auditing-in-one-function}}
For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pyspark.sql} \PYG{k+kn}{import} \PYG{n}{SparkSession}

\PYG{n}{spark} \PYG{o}{=} \PYG{n}{SparkSession} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{builder} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{appName}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Python Spark regression example}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{spark.some.config.option}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some\PYGZhy{}value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{getOrCreate}\PYG{p}{(}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} from PySparkAudit import dtypes\PYGZus{}class, hist\PYGZus{}plot, bar\PYGZus{}plot, freq\PYGZus{}items,feature\PYGZus{}len}
\PYG{c+c1}{\PYGZsh{} from PySparkAudit import dataset\PYGZus{}summary, rates, trend\PYGZus{}plot}

\PYG{c+c1}{\PYGZsh{} path = \PYGZsq{}/home/feng/Desktop\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} import PySpark Audit function}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{auditing}

\PYG{c+c1}{\PYGZsh{} load dataset}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{csv}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Heart.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{encoding}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{UTF\PYGZhy{}8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{comment}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{header}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{inferSchema}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} auditing in one function }
\PYG{k}{print}\PYG{p}{(}\PYG{n}{auditing}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

Result:


\subsection{print in bash}
\label{\detokenize{demo:print-in-bash}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The audited results summary audited\PYGZus{}results.xlsx was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The correlation matrix plot Corr.png was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The Histograms plot Histograms.pdf was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited
Histograms plots are \PYG{k}{done}!
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The Bar plot Bar\PYGZus{}plots.pdf was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited
Caution: no date features in the dataset!!!
Generate all audited results \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{29}.093122243881226 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The auditing processes are DONE!!!
\PYG{o}{(}   feature  dtypes  row\PYGZus{}count    ...     rate\PYGZus{}neg  rate\PYGZus{}zero  rate\PYGZus{}pos
\PYG{l+m}{0}      Age     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000
\PYG{l+m}{1}      Sex     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.320132  \PYG{l+m}{0}.679868
\PYG{l+m}{2}   RestBP     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000
\PYG{l+m}{3}     Chol     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000
\PYG{l+m}{4}      Fbs     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.851485  \PYG{l+m}{0}.148515
\PYG{l+m}{5}  RestECG     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.498350  \PYG{l+m}{0}.501650
\PYG{l+m}{6}    MaxHR     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000
\PYG{l+m}{7}    ExAng     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.673267  \PYG{l+m}{0}.326733
\PYG{l+m}{8}  Oldpeak  double        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.326733  \PYG{l+m}{0}.673267
\PYG{l+m}{9}    Slope     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000

\PYG{o}{[}\PYG{l+m}{10} rows x \PYG{l+m}{22} columns\PYG{o}{]},      feature  dtypes     ...      rate\PYGZus{}null  rate\PYGZus{}empty
\PYG{l+m}{0}  ChestPain  string     ...            \PYG{l+m}{0}.0         \PYG{l+m}{0}.0
\PYG{l+m}{1}         Ca  string     ...            \PYG{l+m}{0}.0         \PYG{l+m}{0}.0
\PYG{l+m}{2}       Thal  string     ...            \PYG{l+m}{0}.0         \PYG{l+m}{0}.0
\PYG{l+m}{3}        AHD  string     ...            \PYG{l+m}{0}.0         \PYG{l+m}{0}.0

\PYG{o}{[}\PYG{l+m}{4} rows x \PYG{l+m}{12} columns\PYG{o}{]},               Age       Sex    RestBP    ...        ExAng   Oldpeak     Slope
Age      \PYG{l+m}{1}.000000 \PYGZhy{}0.097542  \PYG{l+m}{0}.284946    ...     \PYG{l+m}{0}.091661  \PYG{l+m}{0}.203805  \PYG{l+m}{0}.161770
Sex     \PYGZhy{}0.097542  \PYG{l+m}{1}.000000 \PYGZhy{}0.064456    ...     \PYG{l+m}{0}.146201  \PYG{l+m}{0}.102173  \PYG{l+m}{0}.037533
RestBP   \PYG{l+m}{0}.284946 \PYGZhy{}0.064456  \PYG{l+m}{1}.000000    ...     \PYG{l+m}{0}.064762  \PYG{l+m}{0}.189171  \PYG{l+m}{0}.117382
Chol     \PYG{l+m}{0}.208950 \PYGZhy{}0.199915  \PYG{l+m}{0}.130120    ...     \PYG{l+m}{0}.061310  \PYG{l+m}{0}.046564 \PYGZhy{}0.004062
Fbs      \PYG{l+m}{0}.118530  \PYG{l+m}{0}.047862  \PYG{l+m}{0}.175340    ...     \PYG{l+m}{0}.025665  \PYG{l+m}{0}.005747  \PYG{l+m}{0}.059894
RestECG  \PYG{l+m}{0}.148868  \PYG{l+m}{0}.021647  \PYG{l+m}{0}.146560    ...     \PYG{l+m}{0}.084867  \PYG{l+m}{0}.114133  \PYG{l+m}{0}.133946
MaxHR   \PYGZhy{}0.393806 \PYGZhy{}0.048663 \PYGZhy{}0.045351    ...    \PYGZhy{}0.378103 \PYGZhy{}0.343085 \PYGZhy{}0.385601
ExAng    \PYG{l+m}{0}.091661  \PYG{l+m}{0}.146201  \PYG{l+m}{0}.064762    ...     \PYG{l+m}{1}.000000  \PYG{l+m}{0}.288223  \PYG{l+m}{0}.257748
Oldpeak  \PYG{l+m}{0}.203805  \PYG{l+m}{0}.102173  \PYG{l+m}{0}.189171    ...     \PYG{l+m}{0}.288223  \PYG{l+m}{1}.000000  \PYG{l+m}{0}.577537
Slope    \PYG{l+m}{0}.161770  \PYG{l+m}{0}.037533  \PYG{l+m}{0}.117382    ...     \PYG{l+m}{0}.257748  \PYG{l+m}{0}.577537  \PYG{l+m}{1}.000000

\PYG{o}{[}\PYG{l+m}{10} rows x \PYG{l+m}{10} columns\PYG{o}{]}\PYG{o}{)}

Process finished with \PYG{n+nb}{exit} code \PYG{l+m}{0}
\end{sphinxVerbatim}


\subsection{Audited results folder}
\label{\detokenize{demo:audited-results-folder}}\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_folder}.png}
\end{figure}
\end{quote}

The files in \sphinxcode{\sphinxupquote{00-audited\_results.xlsx}}:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Dataset\_summary

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_excel1}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
Numeric\_summary

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_excel2}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Category\_summary

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_excel3}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Correlation\_matrix

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_excel4}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
Histograms in \sphinxcode{\sphinxupquote{Histograms.pdf}}

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{hists}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{5}
\item {} 
Barplots in \sphinxcode{\sphinxupquote{Bar\_plots.pdf}}

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{bars}.png}
\end{figure}
\end{quote}


\section{Auditing on Big Dataset}
\label{\detokenize{demo:auditing-on-big-dataset}}
In this section, we will demonstrate the auditing performance and audited results on the big data set.
The data set is \sphinxcode{\sphinxupquote{Spanish High Speed Rail tickets pricing}}.  It is available at :
\sphinxurl{https://www.kaggle.com/thegurus/spanish-high-speed-rail-system-ticket-pricing}. This data set has 2579771
samples and 10 features.

From the following CPU time, you will see most
of the time was spent on plotting the histograms. If your time and memory are limited, we will suggest
you to use \sphinxcode{\sphinxupquote{sample\_size}} to generate the subset of the the dataset to plot histograms.

For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pyspark.sql} \PYG{k+kn}{import} \PYG{n}{SparkSession}

\PYG{n}{spark} \PYG{o}{=} \PYG{n}{SparkSession} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{builder} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{appName}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Python Spark regression example}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{spark.some.config.option}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some\PYGZhy{}value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{getOrCreate}\PYG{p}{(}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} from PySparkAudit import dtypes\PYGZus{}class, hist\PYGZus{}plot, bar\PYGZus{}plot, freq\PYGZus{}items,feature\PYGZus{}len}
\PYG{c+c1}{\PYGZsh{} from PySparkAudit import dataset\PYGZus{}summary, rates, trend\PYGZus{}plot}

\PYG{c+c1}{\PYGZsh{} Audited results output path}
\PYG{n}{out\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/home/feng/Desktop}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} import PySpark Audit function}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{auditing}

\PYG{c+c1}{\PYGZsh{} load dataset}
\PYG{c+c1}{\PYGZsh{} Spanish High Speed Rail tickets pricing \PYGZhy{} Renfe (\PYGZti{}2.58M)}
\PYG{c+c1}{\PYGZsh{} https://www.kaggle.com/thegurus/spanish\PYGZhy{}high\PYGZhy{}speed\PYGZhy{}rail\PYGZhy{}system\PYGZhy{}ticket\PYGZhy{}pricing}

\PYG{n}{data} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{csv}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/home/feng/Downloads/renfe.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{encoding}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{UTF\PYGZhy{}8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{comment}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{header}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{inferSchema}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} auditing in one function}
\PYG{n}{auditing}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n}{output\PYGZus{}dir}\PYG{o}{=}\PYG{n}{out\PYGZus{}path}\PYG{p}{,} \PYG{n}{tracking}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\end{sphinxVerbatim}

Result:


\subsection{print in bash}
\label{\detokenize{demo:id1}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The audited results summary audited\PYGZus{}results.xlsx was located at:
/home/feng/Desktop/Audited
Generate data \PYG{n+nb}{set} summary \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{60}.535009145736694 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
Collecting data types.... Please be patient!
Generate counts \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{0}.0016515254974365234 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
Collecting features\PYG{l+s+s1}{\PYGZsq{} counts.... Please be patient!}
\PYG{l+s+s1}{Generate counts took = 6.502962350845337 s}
\PYG{l+s+s1}{================================================================}
\PYG{l+s+s1}{Collecting data frame description.... Please be patient!}
\PYG{l+s+s1}{Generate data frame description took = 1.5562639236450195 s}
\PYG{l+s+s1}{================================================================}
\PYG{l+s+s1}{Calculating percentiles.... Please be patient!}
\PYG{l+s+s1}{Generate percentiles took = 19.76785445213318 s}
\PYG{l+s+s1}{================================================================}
\PYG{l+s+s1}{Calculating features\PYGZsq{}} length.... Please be patient!
Generate features\PYG{l+s+s1}{\PYGZsq{} length took = 4.953453540802002 s}
\PYG{l+s+s1}{================================================================}
\PYG{l+s+s1}{Calculating top 5 frequent items.... Please be patient!}
\PYG{l+s+s1}{Generate rates took: 4.761325359344482 s}
\PYG{l+s+s1}{================================================================}
\PYG{l+s+s1}{Calculating rates.... Please be patient!}
\PYG{l+s+s1}{Generate rates took: 17.201056718826294 s}
\PYG{l+s+s1}{Auditing numerical data took = 54.77840781211853 s}
\PYG{l+s+s1}{================================================================}
\PYG{l+s+s1}{Collecting data types.... Please be patient!}
\PYG{l+s+s1}{Generate counts took = 0.001623392105102539 s}
\PYG{l+s+s1}{================================================================}
\PYG{l+s+s1}{Collecting features\PYGZsq{}} counts.... Please be patient!
Generate counts \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{12}.59226107597351 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
Calculating features\PYG{l+s+s1}{\PYGZsq{} length.... Please be patient!}
\PYG{l+s+s1}{Generate features\PYGZsq{}} length \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{5}.332952976226807 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
Calculating top \PYG{l+m}{5} frequent items.... Please be patient!
Generate rates took: \PYG{l+m}{6}.832213878631592 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
Calculating rates.... Please be patient!
Generate rates took: \PYG{l+m}{23}.704302072525024 s
Auditing categorical data \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{48}.484763622283936 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The correlation matrix plot Corr.png was located at:
/home/feng/Desktop/Audited
Calculating correlation matrix... Please be patient!
Generate correlation matrix \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{19}.61273431777954 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The Histograms plots *.png were located at:
/home/feng/Desktop/Audited/02\PYGZhy{}hist
Plotting histograms of \PYGZus{}c0.... Please be patient!
Plotting histograms of price.... Please be patient!
Histograms plots are DONE!!!
Generate histograms plots \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{160}.3421311378479 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The Bar plot Bar\PYGZus{}plots.pdf was located at:
/home/feng/Desktop/Audited
Plotting barplot of origin.... Please be patient!
Plotting barplot of destination.... Please be patient!
Plotting barplot of train\PYGZus{}type.... Please be patient!
Plotting barplot of train\PYGZus{}class.... Please be patient!
Plotting barplot of fare.... Please be patient!
Plotting barplot of insert\PYGZus{}date.... Please be patient!
Plotting barplot of start\PYGZus{}date.... Please be patient!
Plotting barplot of end\PYGZus{}date.... Please be patient!
Bar plots are DONE!!!
Generate bar plots \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{24}.17994236946106 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The Trend plot Trend\PYGZus{}plots.pdf was located at:
/home/feng/Desktop/Audited
Plotting trend plot of \PYGZus{}c0.... Please be patient!
Plotting trend plot of price.... Please be patient!
Trend plots are DONE!!!
Generate trend plots \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{11}.697550296783447 s
Generate all the figures \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{196}.25823402404785 s
Generate all audited results \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{379}.73954820632935 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The auditing processes are DONE!!!
\end{sphinxVerbatim}


\subsection{Audited results folder}
\label{\detokenize{demo:id2}}\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{demo3_folder}.png}
\end{figure}
\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
       .,,.
     ,\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;},
    .\PYGZhy{}\PYG{l+s+s1}{\PYGZsq{}{}`{}`;\PYGZhy{}\PYGZsq{}}\PYG{o}{)}\PYG{p}{;}\PYG{p}{;}.
   /\PYG{l+s+s1}{\PYGZsq{}  .\PYGZhy{}.  /*;;}
\PYG{l+s+s1}{ .\PYGZsq{}}    \PYG{l+s+se}{\PYGZbs{}d}    \PYG{l+s+se}{\PYGZbs{};}\PYG{p}{;}               .\PYG{p}{;}\PYG{p}{;}\PYG{p}{;},
/ o      \PYG{l+s+sb}{{}`}    \PYG{l+s+se}{\PYGZbs{};}    ,\PYGZus{}\PYGZus{}.     ,\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;},
\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYGZus{}, \PYGZus{}.\PYGZus{}\PYGZus{},\PYG{l+s+s1}{\PYGZsq{}   \PYGZbs{}\PYGZus{}.\PYGZhy{}\PYGZsq{}}\PYG{o}{)} \PYGZus{}\PYGZus{}\PYG{o}{)}\PYGZhy{}\PYGZhy{}.\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;},
 \PYG{l+s+sb}{{}`}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}\PYG{l+s+sb}{{}`}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{l+s+se}{\PYGZbs{} }      /\PYGZhy{}\PYG{l+s+s1}{\PYGZsq{})\PYGZus{}) \PYGZus{}\PYGZus{})  {}`\PYGZbs{}\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{};;;;;;}
\PYG{l+s+s1}{    ;*;;;        \PYGZhy{}\PYGZsq{}}\PYG{o}{)} \PYG{l+s+sb}{{}`}\PYG{o}{)}\PYGZus{}\PYG{o}{)}  \PYG{p}{\textbar{}}\PYG{l+s+se}{\PYGZbs{} }\PYG{p}{\textbar{}}  \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}
    \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{\textbar{}}        \PYG{l+s+sb}{{}`}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYG{l+s+sb}{{}`}    O \PYG{p}{\textbar{}} \PYG{p}{\textbar{}} \PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}
    *\PYG{p}{;}*\PYG{p}{;}\PYG{l+s+se}{\PYGZbs{}\textbar{}}                 O  / \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*
   \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}/\PYG{p}{\textbar{}}    .\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYG{l+s+se}{\PYGZbs{} }     / \PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}
  \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}/ \PYG{l+s+se}{\PYGZbs{} }   \PYG{p}{\textbar{}}        \PYG{l+s+s1}{\PYGZsq{}.   ({}`. ;;;*;;;}
\PYG{l+s+s1}{  ;;;;;\PYGZsq{}}. \PYG{p}{;}   \PYG{p}{\textbar{}}          \PYG{o}{)}   \PYG{l+s+se}{\PYGZbs{} }\PYG{p}{\textbar{}} \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}
  ,\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{l+s+se}{\PYGZbs{}/}   \PYG{p}{\textbar{}}.        /   /\PYG{l+s+sb}{{}`} \PYG{p}{\textbar{}} \PYG{l+s+s1}{\PYGZsq{};;;*;}
\PYG{l+s+s1}{   ;;;;;;/    \textbar{}/       /   /\PYGZus{}\PYGZus{}/   \PYGZsq{}}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}
   \PYG{l+s+s1}{\PYGZsq{}*wf*/     \textbar{}       /    \textbar{}      ;*;}
\PYG{l+s+s1}{        {}`\PYGZdq{}\PYGZdq{}\PYGZdq{}\PYGZdq{}{}`        {}`\PYGZdq{}\PYGZdq{}\PYGZdq{}\PYGZdq{}{}`     ;\PYGZsq{}}
\end{sphinxVerbatim}


\chapter{Main Reference}
\label{\detokenize{reference:main-reference}}\label{\detokenize{reference:reference}}\label{\detokenize{reference::doc}}
\begin{sphinxthebibliography}{PySparkA}
\bibitem[PyAudit]{reference:pyaudit}
Wenqiang Feng and Ming Chen. \sphinxhref{https://runawayhorse001.github.io/PyAudit/}{Python Data Audit Library API}, 2019.
\bibitem[PySparkAudit]{reference:pysparkaudit}
Wenqiang Feng and Yiming Xu. \sphinxhref{https://runawayhorse001.github.io/PySparkAudit/}{PySpark Data Audit Library API}, 2019.
\end{sphinxthebibliography}



\renewcommand{\indexname}{Index}
\printindex
\end{document}