%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,12pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{2}

\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{dsfont}
\def\Z{\mathbb{Z}}
\def\R{\mathbb{R}}
\def\bX{\mathbf{X}}
\def\X{\mathbf{X}}
\def\By{\mathbf{y}}
\def\Bbeta{\boldsymbol{\beta}}
\def\bU{\mathbf{U}}
\def\bV{\mathbf{V}}
\def\V1{\mathds{1}}
\def\hU{\mathbf{\hat{U}}}
\def\hS{\mathbf{\hat{\Sigma}}}
\def\hV{\mathbf{\hat{V}}}
\def\E{\mathbf{E}}
\def\F{\mathbf{F}}
\def\x{\mathbf{x}}
\def\h{\mathbf{h}}
\def\v{\mathbf{v}}
\def\nv{\mathbf{v^{{f -}}}}
\def\nh{\mathbf{h^{{f -}}}}
\def\s{\mathbf{s}}
\def\b{\mathbf{b}}
\def\c{\mathbf{c}}
\def\W{\mathbf{W}}
\def\C{\mathbf{C}}
\def\P{\mathbf{P}}
\def\T{{\bf \mathcal T}}
\def\B{{\bf \mathcal B}}
\def\euler{\ e^{i\pi} + 1 = 0}


\title{PySparkAudit: PySpark Data Audit}
\date{July 01, 2019}
\release{}
\author{Wenqiang Feng and Yiming Xu}
\newcommand{\sphinxlogo}{\sphinxincludegraphics{logo.png}\par}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\maketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}\phantomsection\label{\detokenize{index:index}}\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{logo}.png}
\end{figure}
\end{quote}

Welcome to our \sphinxstylestrong{PySparkAudit: PySpark Data Audit Library API}! The PDF version can be downloaded from \sphinxhref{PySparkAudit.pdf}{HERE}.

You can install the \sphinxcode{\sphinxupquote{PySparkAudit}} from {[}PyPI{]}(\sphinxurl{https://pypi.org/project/PySparkAudit}):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
pip install PySparkAudit
\end{sphinxVerbatim}




\chapter{Preface}
\label{\detokenize{preface:preface}}\label{\detokenize{preface:id1}}\label{\detokenize{preface::doc}}
\begin{sphinxadmonition}{note}{Chinese proverb}

Good tools are prerequisite to the successful execution of a job. \textendash{} old Chinese proverb
\end{sphinxadmonition}


\section{About}
\label{\detokenize{preface:about}}

\subsection{About this API}
\label{\detokenize{preface:about-this-api}}
This document is the \sphinxcode{\sphinxupquote{API}} book for our \sphinxstylestrong{PySparkAudit}: PySpark Data Audit Library \sphinxcite{reference:pysparkaudit} API. The PDF version can be downloaded from \sphinxhref{PySparkAudit.pdf}{HERE}. \sphinxstylestrong{You may download and distribute it. Please be aware, however, that the note contains typos as well as inaccurate or incorrect description.}

The \sphinxcode{\sphinxupquote{API}} assumes that the reader has a preliminary knowledge of \sphinxcode{\sphinxupquote{python}} programing and \sphinxcode{\sphinxupquote{Linux}}. And this document is generated automatically by using \sphinxhref{http://sphinx.pocoo.org}{sphinx}.

The python version \sphinxstylestrong{PyAudit}: Python Data Audit Library API can be found at \sphinxcite{reference:pyaudit}.


\subsection{About the author}
\label{\detokenize{preface:about-the-author}}\begin{itemize}
\item {} 
\sphinxstylestrong{Wenqiang Feng}
\begin{itemize}
\item {} 
Sr. Data Scientist and PhD in Mathematics

\item {} 
University of Tennessee at Knoxville

\item {} 
Webpage: \sphinxurl{http://web.utk.edu/~wfeng1/}

\item {} 
Email: \sphinxhref{mailto:von198@gmail.com}{von198@gmail.com}

\end{itemize}

\item {} 
\sphinxstylestrong{Yiming Xu}
\begin{itemize}
\item {} 
Data Scientist and Master of Data Science

\item {} 
Harvard University

\item {} 
Email:  \sphinxhref{mailto:yimingxu@g.harvard.edu}{yimingxu@g.harvard.edu}

\end{itemize}

\item {} 
\sphinxstylestrong{Biography}

Wenqiang Feng is Data Scientist within DST’s Applied Analytics Group. Dr. Feng’s responsibilities include providing DST clients with access to cutting-edge skills and technologies, including Big Data analytic solutions, advanced analytic and data enhancement techniques and modeling.

Dr. Feng has deep analytic expertise in data mining, analytic systems, machine learning algorithms, business intelligence, and applying Big Data tools to strategically solve industry problems in a cross-functional business. Before joining DST, Dr. Feng was an IMA Data Science Fellow at The Institute for Mathematics and its Applications (IMA) at the University of Minnesota. While there, he helped startup companies make marketing decisions based on deep predictive analytics.

Dr. Feng graduated from University of Tennessee, Knoxville, with Ph.D. in Computational Mathematics and Master’s degree in Statistics. He also holds Master’s degree in Computational Mathematics from Missouri University of Science and Technology (MST) and Master’s degree in Applied Mathematics from the University of Science and Technology of China (USTC).

\item {} 
\sphinxstylestrong{Declaration}

The work of Wenqiang Feng was supported by the IMA, while working at IMA. However, any opinion, finding, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the IMA, UTK, DST and Harvard University.

\end{itemize}


\section{Acknowledgement}
\label{\detokenize{preface:acknowledgement}}
At here, Wenqiang Feng would like to thank \sphinxstylestrong{Weiyu Wang} at Missouri University of Science and Technology and
\sphinxstylestrong{Jiangtao (Lotto) Xie} at Purdue University for the unit testing and valuable disscussion.


\section{Feedback and suggestions}
\label{\detokenize{preface:feedback-and-suggestions}}
Your comments and suggestions are highly appreciated. I am more than happy to receive
corrections, suggestions or feedbacks through email (Wenqiang Feng: \sphinxhref{mailto:von198@gmail.com}{von198@gmail.com} and Yiming Xu: \sphinxhref{mailto:yimingxu@g.harvard.edu}{yimingxu@g.harvard.edu}) for improvements.


\chapter{How to Install}
\label{\detokenize{install:how-to-install}}\label{\detokenize{install:install}}\label{\detokenize{install::doc}}

\section{Install with \sphinxstyleliteralintitle{\sphinxupquote{pip}}}
\label{\detokenize{install:install-with-pip}}
You can install the \sphinxcode{\sphinxupquote{PySparkAudit}} from {[}PyPI{]}(\sphinxurl{https://pypi.org/project/PySparkAudit}):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
pip install PySparkAudit
\end{sphinxVerbatim}


\section{Install from Repo}
\label{\detokenize{install:install-from-repo}}

\subsection{Clone the Repository}
\label{\detokenize{install:clone-the-repository}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
git clone https://github.com/runawayhorse001/PySparkAudit.git
\end{sphinxVerbatim}


\subsection{Install}
\label{\detokenize{install:id1}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{cd} PySparkAudit
pip install \PYGZhy{}r requirements.txt
python setup.py install
\end{sphinxVerbatim}


\subsection{Uninstall}
\label{\detokenize{install:uninstall}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
pip uninstall statspy
\end{sphinxVerbatim}


\subsection{Test}
\label{\detokenize{install:test}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{cd} PySparkAudit/test
python test.py
\end{sphinxVerbatim}

\sphinxcode{\sphinxupquote{test.py}}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pyspark.sql} \PYG{k+kn}{import} \PYG{n}{SparkSession}

\PYG{n}{spark} \PYG{o}{=} \PYG{n}{SparkSession} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{builder} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{appName}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Python Spark regression example}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{spark.some.config.option}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some\PYGZhy{}value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{getOrCreate}\PYG{p}{(}\PYG{p}{)}


\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{dtypes\PYGZus{}class}\PYG{p}{,} \PYG{n}{hist\PYGZus{}plot}\PYG{p}{,} \PYG{n}{bar\PYGZus{}plot}\PYG{p}{,} \PYG{n}{freq\PYGZus{}items}\PYG{p}{,}\PYG{n}{feature\PYGZus{}len}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{dataset\PYGZus{}summary}\PYG{p}{,} \PYG{n}{rates}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{trend\PYGZus{}plot}\PYG{p}{,} \PYG{n}{auditing}
\PYG{c+c1}{\PYGZsh{} path = \PYGZsq{}/home/feng/Desktop\PYGZsq{}}


\PYG{n}{data} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{csv}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Heart.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{encoding}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{UTF\PYGZhy{}8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{comment}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{header}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{inferSchema}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}

\PYG{k}{print}\PYG{p}{(}\PYG{n}{auditing}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Audited Results}
\label{\detokenize{install:audited-results}}\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_folder}.png}
\end{figure}
\end{quote}


\chapter{PySpark Data Audit Functions}
\label{\detokenize{basics:pyspark-data-audit-functions}}\label{\detokenize{basics:basics}}\label{\detokenize{basics::doc}}

\section{Basic Functions}
\label{\detokenize{basics:basic-functions}}

\subsection{mkdir}
\label{\detokenize{basics:mkdir}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{mkdir}}}{\emph{path}}{}
Make a new directory. if it’s exist, keep the old files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{path}} \textendash{} the directory path

\end{description}\end{quote}

\end{fulllineitems}



\subsection{mkdir\_clean}
\label{\detokenize{basics:mkdir-clean}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{mkdir\_clean}}}{\emph{path}}{}
Make a new directory. if it’s exist, remove the old files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{path}} \textendash{} the directory path

\end{description}\end{quote}

\end{fulllineitems}



\subsection{df\_merge}
\label{\detokenize{basics:df-merge}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{df\_merge}}}{\emph{dfs}, \emph{key}, \emph{how='left'}}{}
Merge multiple pandas data frames with same key.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{dfs}} \textendash{} name list of the data frames

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{key}} \textendash{} key for join

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{how}} \textendash{} method for join, the default value is left

\end{itemize}

\item[{Returns}] \leavevmode
merged data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{data\_types}
\label{\detokenize{basics:data-types}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{data\_types}}}{\emph{df\_in}, \emph{tracking=False}}{}
Generate the data types of the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
data types pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{dtypes\_class}
\label{\detokenize{basics:dtypes-class}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{dtypes\_class}}}{\emph{df\_in}}{}
Generate the data type categories: numerical, categorical, date and unsupported category.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item[{Returns}] \leavevmode
data type categories

\end{description}\end{quote}

\end{fulllineitems}



\subsection{counts}
\label{\detokenize{basics:counts}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{counts}}}{\emph{df\_in}, \emph{tracking=False}}{}
Generate the row counts and not null rows and distinct counts for each feature.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the counts in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{describe}
\label{\detokenize{basics:describe}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{describe}}}{\emph{df\_in}, \emph{columns=None}, \emph{tracking=False}}{}
Generate the simple data frame description using \(.describe()\) function in pyspark.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the description in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{percentiles}
\label{\detokenize{basics:percentiles}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{percentiles}}}{\emph{df\_in}, \emph{deciles=False}, \emph{tracking=False}}{}
Generate the percentiles for rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{deciles}} \textendash{} the flag for generate the deciles

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
percentiles in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{feature\_len}
\label{\detokenize{basics:feature-len}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{feature\_len}}}{\emph{df\_in}, \emph{tracking=False}}{}
Generate feature length statistical results for each feature in the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the feature length statistical results in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{freq\_items}
\label{\detokenize{basics:freq-items}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{freq\_items}}}{\emph{df\_in}, \emph{top\_n=5}, \emph{tracking=False}}{}
Generate the top\_n frequent items in for each feature in the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent item

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode


\end{description}\end{quote}

\end{fulllineitems}



\subsection{rates}
\label{\detokenize{basics:rates}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{rates}}}{\emph{df\_in}, \emph{columns=None}, \emph{numeric=True}, \emph{tracking=False}}{}
Generate the null, empty, negative, zero and  positive value rates and feature variance for
each feature in the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{numeric}} \textendash{} the flag for numerical rdd data frame, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the null, empty, negative, zero and  positive value rates and feature variance
in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{corr\_matrix}
\label{\detokenize{basics:corr-matrix}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{corr\_matrix}}}{\emph{df\_in}, \emph{method='pearson'}, \emph{output\_dir=None}, \emph{rotation=True}, \emph{display=False}, \emph{tracking=False}}{}
Generate the correlation matrix and heat map plot for rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{method}} \textendash{} the method which applied to calculate the correlation matrix: pearson or spearman.
the default value is pearson

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the correlation matrix in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\section{Plot Functions}
\label{\detokenize{basics:plot-functions}}

\subsection{hist\_plot}
\label{\detokenize{basics:hist-plot}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{hist\_plot}}}{\emph{df\_in}, \emph{bins=50}, \emph{output\_dir=None}, \emph{sample\_size=None}, \emph{display=False}, \emph{tracking=False}}{}
Histogram plot for the numerical features in the rdd data frame. \sphinxstylestrong{This part is super time and
memory consuming.} If the data size is larger than 10,000, the histograms will be saved in .pdf
format. Otherwise, the histograms will be saved in .png format in hist folder.

If your time and memory are limited, you can use sample\_size to generate the subset of the data
frame to generate the histograms.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{bins}} \textendash{} the number of bins for generate the bar plots

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sample\_size}} \textendash{} the size for generate the subset from the rdd data frame, the
default value none

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{bar\_plot}
\label{\detokenize{basics:bar-plot}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{bar\_plot}}}{\emph{df\_in}, \emph{top\_n=20}, \emph{rotation=True}, \emph{output\_dir=None}, \emph{display=False}, \emph{tracking=False}}{}
Bar plot for the categorical features in the rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent feature to show in the bar plot

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{trend\_plot}
\label{\detokenize{basics:trend-plot}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{trend\_plot}}}{\emph{df\_in}, \emph{types='day'}, \emph{d\_time=None}, \emph{rotation=True}, \emph{output\_dir=None}, \emph{display=False}, \emph{tracking=False}}{}
Trend plot for the aggregated time series data if the rdd data frame has date features and numerical features.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{types}} \textendash{} the types for time feature aggregation: day, month, year, the default value is day

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{d\_time}} \textendash{} the specific feature name of the date feature, the default value
is the first date feature in the rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\section{Summary Functions}
\label{\detokenize{basics:summary-functions}}

\subsection{dataset\_summary}
\label{\detokenize{basics:dataset-summary}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{dataset\_summary}}}{\emph{df\_in}, \emph{tracking=False}}{}
The data set basics summary.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
data set summary in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{numeric\_summary}
\label{\detokenize{basics:numeric-summary}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{numeric\_summary}}}{\emph{df\_in}, \emph{columns=None}, \emph{deciles=False}, \emph{top\_n=5}, \emph{tracking=False}}{}
The auditing function for numerical rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{deciles}} \textendash{} the flag for generate the deciles

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent item

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the audited results for the numerical features in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\subsection{category\_summary}
\label{\detokenize{basics:category-summary}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{category\_summary}}}{\emph{df\_in}, \emph{columns=None}, \emph{top\_n=5}, \emph{tracking=False}}{}
The auditing function for categorical rdd data frame.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent item

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the audited results for the categorical features in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\section{Auditing Function}
\label{\detokenize{basics:auditing-function}}

\subsection{auditing}
\label{\detokenize{basics:auditing}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{auditing}}}{\emph{df\_in}, \emph{writer=None}, \emph{columns=None}, \emph{deciles=False}, \emph{top\_freq\_item=5}, \emph{bins=50}, \emph{top\_cat\_item=20}, \emph{method='pearson'}, \emph{output\_dir=None}, \emph{types='day'}, \emph{d\_time=None}, \emph{rotation=True}, \emph{sample\_size=None}, \emph{display=False}, \emph{tracking=False}}{}
The wrapper of auditing functions.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{writer}} \textendash{} the writer for excel output

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{columns}} \textendash{} the specific feature columns, the default value is None

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{deciles}} \textendash{} the flag for generate the deciles

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_freq\_item}} \textendash{} the number of the most frequent item

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{bins}} \textendash{} the number of bins for generate the bar plots

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_cat\_item}} \textendash{} the number of the most frequent feature to show in the bar plot

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{method}} \textendash{} the method which applied to calculate the correlation matrix: pearson or spearman.
the default value is pearson

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{types}} \textendash{} the types for time feature aggregation: day, month, year, the default value is day

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{d\_time}} \textendash{} the specific feature name of the date feature, the default value
is the first date feature in the rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sample\_size}} \textendash{} the size for generate the subset from the rdd data frame, the
default value none

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\item[{Returns}] \leavevmode
the all audited results in pandas data frame

\end{description}\end{quote}

\end{fulllineitems}



\section{Plotting Function}
\label{\detokenize{basics:plotting-function}}

\subsection{fig\_plots}
\label{\detokenize{basics:fig-plots}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{PySparkAudit.PySparkAudit.}}\sphinxbfcode{\sphinxupquote{fig\_plots}}}{\emph{df\_in}, \emph{output\_dir=None}, \emph{bins=50}, \emph{top\_n=20}, \emph{types='day'}, \emph{d\_time=None}, \emph{rotation=True}, \emph{sample\_size=None}, \emph{display=False}, \emph{tracking=False}}{}
The wrapper for the plot functions.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{df\_in}} \textendash{} the input rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{output\_dir}} \textendash{} the out put directory, the default value is the current working directory

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{bins}} \textendash{} the number of bins for generate the bar plots

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{top\_n}} \textendash{} the number of the most frequent feature to show in the bar plot

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{types}} \textendash{} the types for time feature aggregation: day, month, year, the default value is day

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{d\_time}} \textendash{} the specific feature name of the date feature, the default value
is the first date feature in the rdd data frame

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rotation}} \textendash{} the flag for rotating the xticks in the plot, the default value is True

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sample\_size}} \textendash{} the size for generate the subset from the rdd data frame, the
default value none

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{display}} \textendash{} the flag for displaying the figures, the default value is False

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tracking}} \textendash{} the flag for displaying CPU time, the default value is False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\chapter{Auditing Demos}
\label{\detokenize{demo:auditing-demos}}\label{\detokenize{demo:demo}}\label{\detokenize{demo::doc}}
The following demos are designed to show how to use \sphinxcode{\sphinxupquote{PySparkAudit}} to aduit rdd \sphinxcode{\sphinxupquote{DataFrame}}.


\section{Auditing function by function}
\label{\detokenize{demo:auditing-function-by-function}}
For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pyspark.sql} \PYG{k+kn}{import} \PYG{n}{SparkSession}

\PYG{n}{spark} \PYG{o}{=} \PYG{n}{SparkSession} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{builder} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{appName}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Python Spark regression example}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{spark.some.config.option}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some\PYGZhy{}value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{getOrCreate}\PYG{p}{(}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} import PySpark Audit functions}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{data\PYGZus{}types}\PYG{p}{,} \PYG{n}{hist\PYGZus{}plot}\PYG{p}{,} \PYG{n}{bar\PYGZus{}plot}\PYG{p}{,} \PYG{n}{freq\PYGZus{}items}\PYG{p}{,}\PYG{n}{feature\PYGZus{}len}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{dataset\PYGZus{}summary}\PYG{p}{,} \PYG{n}{rates}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{trend\PYGZus{}plot}\PYG{p}{,} \PYG{n}{auditing}

\PYG{c+c1}{\PYGZsh{} load dataset}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{csv}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Heart.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{encoding}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{UTF\PYGZhy{}8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{comment}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{header}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{inferSchema}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} audit function by function}

\PYG{c+c1}{\PYGZsh{} data types}
\PYG{k}{print}\PYG{p}{(}\PYG{n}{data\PYGZus{}types}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} check frequent items}
\PYG{k}{print}\PYG{p}{(}\PYG{n}{freq\PYGZus{}items}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} bar plot for categorical features}
\PYG{n}{bar\PYGZus{}plot}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}  \PYG{n}{display}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\end{sphinxVerbatim}

Result:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
      feature  dtypes
\PYG{l+m}{0}         Age     int
\PYG{l+m}{1}         Sex     int
\PYG{l+m}{2}   ChestPain  string
\PYG{l+m}{3}      RestBP     int
\PYG{l+m}{4}        Chol     int
\PYG{l+m}{5}         Fbs     int
\PYG{l+m}{6}     RestECG     int
\PYG{l+m}{7}       MaxHR     int
\PYG{l+m}{8}       ExAng     int
\PYG{l+m}{9}     Oldpeak  double
\PYG{l+m}{10}      Slope     int
\PYG{l+m}{11}         Ca  string
\PYG{l+m}{12}       Thal  string
\PYG{l+m}{13}        AHD  string
      feature                            freq\PYGZus{}items\PYG{o}{[}value, freq\PYG{o}{]}
\PYG{l+m}{0}         Age  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{58}, \PYG{l+m}{19}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{57}, \PYG{l+m}{17}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{54}, \PYG{l+m}{16}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{59}, \PYG{l+m}{14}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{52}, ...
\PYG{l+m}{1}         Sex                                \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{206}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{97}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{2}   ChestPain  \PYG{o}{[}\PYG{o}{[}asymptomatic, \PYG{l+m}{144}\PYG{o}{]}, \PYG{o}{[}nonanginal, \PYG{l+m}{86}\PYG{o}{]}, \PYG{o}{[}nonty...
\PYG{l+m}{3}      RestBP  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{120}, \PYG{l+m}{37}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{130}, \PYG{l+m}{36}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{140}, \PYG{l+m}{32}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{110}, \PYG{l+m}{19}\PYG{o}{]}, \PYG{o}{[}...
\PYG{l+m}{4}        Chol  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{197}, \PYG{l+m}{6}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{234}, \PYG{l+m}{6}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{204}, \PYG{l+m}{6}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{254}, \PYG{l+m}{5}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{212},...
\PYG{l+m}{5}         Fbs                                \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{258}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{45}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{6}     RestECG                       \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{151}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{2}, \PYG{l+m}{148}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{4}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{7}       MaxHR  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{162}, \PYG{l+m}{11}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{163}, \PYG{l+m}{9}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{160}, \PYG{l+m}{9}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{152}, \PYG{l+m}{8}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{132}...
\PYG{l+m}{8}       ExAng                                \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{204}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{99}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{9}     Oldpeak  \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}.0, \PYG{l+m}{99}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}.2, \PYG{l+m}{17}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{0}.6, \PYG{l+m}{14}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}.0, \PYG{l+m}{14}\PYG{o}{]}, \PYG{o}{[}...
\PYG{l+m}{10}      Slope                      \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{142}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{2}, \PYG{l+m}{140}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{3}, \PYG{l+m}{21}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{11}         Ca     \PYG{o}{[}\PYG{o}{[}\PYG{l+m}{0}, \PYG{l+m}{176}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{1}, \PYG{l+m}{65}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{2}, \PYG{l+m}{38}\PYG{o}{]}, \PYG{o}{[}\PYG{l+m}{3}, \PYG{l+m}{20}\PYG{o}{]}, \PYG{o}{[}NA, \PYG{l+m}{4}\PYG{o}{]}\PYG{o}{]}
\PYG{l+m}{12}       Thal  \PYG{o}{[}\PYG{o}{[}normal, \PYG{l+m}{166}\PYG{o}{]}, \PYG{o}{[}reversable, \PYG{l+m}{117}\PYG{o}{]}, \PYG{o}{[}fixed, \PYG{l+m}{18}\PYG{o}{]}...
\PYG{l+m}{13}        AHD                            \PYG{o}{[}\PYG{o}{[}No, \PYG{l+m}{164}\PYG{o}{]}, \PYG{o}{[}Yes, \PYG{l+m}{139}\PYG{o}{]}\PYG{o}{]}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The Bar plot Bar\PYGZus{}plots.pdf was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited

Process finished with \PYG{n+nb}{exit} code \PYG{l+m}{0}
\end{sphinxVerbatim}

and
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{bars}.png}
\end{figure}
\end{quote}


\section{Auditing in one function}
\label{\detokenize{demo:auditing-in-one-function}}
For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pyspark.sql} \PYG{k+kn}{import} \PYG{n}{SparkSession}

\PYG{n}{spark} \PYG{o}{=} \PYG{n}{SparkSession} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{builder} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{appName}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Python Spark regression example}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{spark.some.config.option}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some\PYGZhy{}value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{getOrCreate}\PYG{p}{(}\PYG{p}{)}


\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{dtypes\PYGZus{}class}\PYG{p}{,} \PYG{n}{hist\PYGZus{}plot}\PYG{p}{,} \PYG{n}{bar\PYGZus{}plot}\PYG{p}{,} \PYG{n}{freq\PYGZus{}items}\PYG{p}{,}\PYG{n}{feature\PYGZus{}len}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{dataset\PYGZus{}summary}\PYG{p}{,} \PYG{n}{rates}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{trend\PYGZus{}plot}\PYG{p}{,} \PYG{n}{auditing}
\PYG{c+c1}{\PYGZsh{} path = \PYGZsq{}/home/feng/Desktop\PYGZsq{}}


\PYG{n}{data} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{csv}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Heart.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{encoding}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{UTF\PYGZhy{}8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{comment}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{header}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{inferSchema}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}

\PYG{k}{print}\PYG{p}{(}\PYG{n}{auditing}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

Result:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
   Age    Sex     ChestPain  RestBP  Chol  ...  Oldpeak  Slope   Ca        Thal  AHD
\PYG{l+m}{0}   \PYG{l+m}{63}   True       typical     \PYG{l+m}{145}   \PYG{l+m}{233}  ...      \PYG{l+m}{2}.3      \PYG{l+m}{3}  \PYG{l+m}{0}.0       fixed   No
\PYG{l+m}{1}   \PYG{l+m}{67}   True  asymptomatic     \PYG{l+m}{160}   \PYG{l+m}{286}  ...      \PYG{l+m}{1}.5      \PYG{l+m}{2}  \PYG{l+m}{3}.0      normal  Yes
\PYG{l+m}{2}   \PYG{l+m}{67}   True  asymptomatic     \PYG{l+m}{120}   \PYG{l+m}{229}  ...      \PYG{l+m}{2}.6      \PYG{l+m}{2}  \PYG{l+m}{2}.0  reversable  Yes
\PYG{l+m}{3}   \PYG{l+m}{37}   True    nonanginal     \PYG{l+m}{130}   \PYG{l+m}{250}  ...      \PYG{l+m}{3}.5      \PYG{l+m}{3}  \PYG{l+m}{0}.0      normal   No
\PYG{l+m}{4}   \PYG{l+m}{41}  False    nontypical     \PYG{l+m}{130}   \PYG{l+m}{204}  ...      \PYG{l+m}{1}.4      \PYG{l+m}{1}  \PYG{l+m}{0}.0      normal   No

\PYG{o}{[}\PYG{l+m}{5} rows x \PYG{l+m}{14} columns\PYG{o}{]}
         feature data\PYGZus{}type  min\PYGZus{}digits  ...  zero\PYGZus{}rate  pos\PYGZus{}rate  neg\PYGZus{}rate
Age          Age     int64           \PYG{l+m}{4}  ...   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000       \PYG{l+m}{0}.0
RestBP    RestBP     int64           \PYG{l+m}{4}  ...   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000       \PYG{l+m}{0}.0
Chol        Chol     int64           \PYG{l+m}{5}  ...   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000       \PYG{l+m}{0}.0
Fbs          Fbs     int64           \PYG{l+m}{3}  ...   \PYG{l+m}{0}.851485  \PYG{l+m}{0}.148515       \PYG{l+m}{0}.0
RestECG  RestECG     int64           \PYG{l+m}{3}  ...   \PYG{l+m}{0}.498350  \PYG{l+m}{0}.501650       \PYG{l+m}{0}.0
MaxHR      MaxHR     int64           \PYG{l+m}{4}  ...   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000       \PYG{l+m}{0}.0
ExAng      ExAng     int64           \PYG{l+m}{3}  ...   \PYG{l+m}{0}.673267  \PYG{l+m}{0}.326733       \PYG{l+m}{0}.0
Oldpeak  Oldpeak   float64           \PYG{l+m}{3}  ...   \PYG{l+m}{0}.326733  \PYG{l+m}{0}.673267       \PYG{l+m}{0}.0
Slope      Slope     int64           \PYG{l+m}{3}  ...   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000       \PYG{l+m}{0}.0
Ca            Ca   float64           \PYG{l+m}{3}  ...   \PYG{l+m}{0}.588629  \PYG{l+m}{0}.411371       \PYG{l+m}{0}.0

\PYG{o}{[}\PYG{l+m}{10} rows x \PYG{l+m}{21} columns\PYG{o}{]}
             feature data\PYGZus{}type  ...          top\PYGZus{}freqs  missing\PYGZus{}rate
Sex              Sex      bool  ...          \PYG{o}{[}\PYG{l+m}{206}, \PYG{l+m}{97}\PYG{o}{]}      \PYG{l+m}{0}.000000
ChestPain  ChestPain    object  ...  \PYG{o}{[}\PYG{l+m}{144}, \PYG{l+m}{86}, \PYG{l+m}{50}, \PYG{l+m}{23}\PYG{o}{]}      \PYG{l+m}{0}.000000
Thal            Thal    object  ...     \PYG{o}{[}\PYG{l+m}{166}, \PYG{l+m}{117}, \PYG{l+m}{18}\PYG{o}{]}      \PYG{l+m}{0}.006601
AHD              AHD    object  ...         \PYG{o}{[}\PYG{l+m}{164}, \PYG{l+m}{139}\PYG{o}{]}      \PYG{l+m}{0}.000000

\PYG{o}{[}\PYG{l+m}{4} rows x \PYG{l+m}{10} columns\PYG{o}{]}
              Age    RestBP      Chol  ...   Oldpeak     Slope        Ca
Age      \PYG{l+m}{1}.000000  \PYG{l+m}{0}.284946  \PYG{l+m}{0}.208950  ...  \PYG{l+m}{0}.203805  \PYG{l+m}{0}.161770  \PYG{l+m}{0}.362605
RestBP   \PYG{l+m}{0}.284946  \PYG{l+m}{1}.000000  \PYG{l+m}{0}.130120  ...  \PYG{l+m}{0}.189171  \PYG{l+m}{0}.117382  \PYG{l+m}{0}.098773
Chol     \PYG{l+m}{0}.208950  \PYG{l+m}{0}.130120  \PYG{l+m}{1}.000000  ...  \PYG{l+m}{0}.046564 \PYGZhy{}0.004062  \PYG{l+m}{0}.119000
Fbs      \PYG{l+m}{0}.118530  \PYG{l+m}{0}.175340  \PYG{l+m}{0}.009841  ...  \PYG{l+m}{0}.005747  \PYG{l+m}{0}.059894  \PYG{l+m}{0}.145478
RestECG  \PYG{l+m}{0}.148868  \PYG{l+m}{0}.146560  \PYG{l+m}{0}.171043  ...  \PYG{l+m}{0}.114133  \PYG{l+m}{0}.133946  \PYG{l+m}{0}.128343
MaxHR   \PYGZhy{}0.393806 \PYGZhy{}0.045351 \PYGZhy{}0.003432  ... \PYGZhy{}0.343085 \PYGZhy{}0.385601 \PYGZhy{}0.264246
ExAng    \PYG{l+m}{0}.091661  \PYG{l+m}{0}.064762  \PYG{l+m}{0}.061310  ...  \PYG{l+m}{0}.288223  \PYG{l+m}{0}.257748  \PYG{l+m}{0}.145570
Oldpeak  \PYG{l+m}{0}.203805  \PYG{l+m}{0}.189171  \PYG{l+m}{0}.046564  ...  \PYG{l+m}{1}.000000  \PYG{l+m}{0}.577537  \PYG{l+m}{0}.295832
Slope    \PYG{l+m}{0}.161770  \PYG{l+m}{0}.117382 \PYGZhy{}0.004062  ...  \PYG{l+m}{0}.577537  \PYG{l+m}{1}.000000  \PYG{l+m}{0}.110119
Ca       \PYG{l+m}{0}.362605  \PYG{l+m}{0}.098773  \PYG{l+m}{0}.119000  ...  \PYG{l+m}{0}.295832  \PYG{l+m}{0}.110119  \PYG{l+m}{1}.000000

\PYG{o}{[}\PYG{l+m}{10} rows x \PYG{l+m}{10} columns\PYG{o}{]}

Process finished with \PYG{n+nb}{exit} code \PYG{l+m}{0}
\end{sphinxVerbatim}

and
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{bars}.png}
\end{figure}
\end{quote}


\section{Auditing function by function}
\label{\detokenize{demo:id1}}
For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{pyspark.sql} \PYG{k+kn}{import} \PYG{n}{SparkSession}

\PYG{n}{spark} \PYG{o}{=} \PYG{n}{SparkSession} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{builder} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{appName}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Python Spark regression example}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{config}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{spark.some.config.option}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{some\PYGZhy{}value}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYGZbs{}
    \PYG{o}{.}\PYG{n}{getOrCreate}\PYG{p}{(}\PYG{p}{)}


\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{dtypes\PYGZus{}class}\PYG{p}{,} \PYG{n}{hist\PYGZus{}plot}\PYG{p}{,} \PYG{n}{bar\PYGZus{}plot}\PYG{p}{,} \PYG{n}{freq\PYGZus{}items}\PYG{p}{,}\PYG{n}{feature\PYGZus{}len}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{dataset\PYGZus{}summary}\PYG{p}{,} \PYG{n}{rates}
\PYG{k+kn}{from} \PYG{n+nn}{PySparkAudit} \PYG{k+kn}{import} \PYG{n}{trend\PYGZus{}plot}\PYG{p}{,} \PYG{n}{auditing}
\PYG{c+c1}{\PYGZsh{} path = \PYGZsq{}/home/feng/Desktop\PYGZsq{}}


\PYG{n}{data} \PYG{o}{=} \PYG{n}{spark}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{csv}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Heart.csv}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                      \PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{encoding}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{UTF\PYGZhy{}8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{comment}\PYG{o}{=}\PYG{n+nb+bp}{None}\PYG{p}{,} \PYG{n}{header}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{inferSchema}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}

\PYG{k}{print}\PYG{p}{(}\PYG{n}{auditing}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n}{display}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

Result:


\subsection{print in bash}
\label{\detokenize{demo:print-in-bash}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The audited results summary audited\PYGZus{}results.xlsx was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The correlation matrix plot Corr.png was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The Histograms plot Histograms.pdf was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited
Histograms plots are \PYG{k}{done}!
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The Bar plot Bar\PYGZus{}plots.pdf was located at:
/home/feng/Dropbox/MyTutorial/PySparkAudit/test/Audited
Caution: no date features in the dataset!!!
Generate all audited results \PYG{n+nv}{took} \PYG{o}{=} \PYG{l+m}{29}.093122243881226 \PYG{n+nv}{s}
\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}\PYG{o}{=}
The auditing processes are DONE!!!
\PYG{o}{(}   feature  dtypes  row\PYGZus{}count    ...     rate\PYGZus{}neg  rate\PYGZus{}zero  rate\PYGZus{}pos
\PYG{l+m}{0}      Age     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000
\PYG{l+m}{1}      Sex     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.320132  \PYG{l+m}{0}.679868
\PYG{l+m}{2}   RestBP     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000
\PYG{l+m}{3}     Chol     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000
\PYG{l+m}{4}      Fbs     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.851485  \PYG{l+m}{0}.148515
\PYG{l+m}{5}  RestECG     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.498350  \PYG{l+m}{0}.501650
\PYG{l+m}{6}    MaxHR     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000
\PYG{l+m}{7}    ExAng     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.673267  \PYG{l+m}{0}.326733
\PYG{l+m}{8}  Oldpeak  double        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.326733  \PYG{l+m}{0}.673267
\PYG{l+m}{9}    Slope     int        \PYG{l+m}{303}    ...          \PYG{l+m}{0}.0   \PYG{l+m}{0}.000000  \PYG{l+m}{1}.000000

\PYG{o}{[}\PYG{l+m}{10} rows x \PYG{l+m}{22} columns\PYG{o}{]},      feature  dtypes     ...      rate\PYGZus{}null  rate\PYGZus{}empty
\PYG{l+m}{0}  ChestPain  string     ...            \PYG{l+m}{0}.0         \PYG{l+m}{0}.0
\PYG{l+m}{1}         Ca  string     ...            \PYG{l+m}{0}.0         \PYG{l+m}{0}.0
\PYG{l+m}{2}       Thal  string     ...            \PYG{l+m}{0}.0         \PYG{l+m}{0}.0
\PYG{l+m}{3}        AHD  string     ...            \PYG{l+m}{0}.0         \PYG{l+m}{0}.0

\PYG{o}{[}\PYG{l+m}{4} rows x \PYG{l+m}{12} columns\PYG{o}{]},               Age       Sex    RestBP    ...        ExAng   Oldpeak     Slope
Age      \PYG{l+m}{1}.000000 \PYGZhy{}0.097542  \PYG{l+m}{0}.284946    ...     \PYG{l+m}{0}.091661  \PYG{l+m}{0}.203805  \PYG{l+m}{0}.161770
Sex     \PYGZhy{}0.097542  \PYG{l+m}{1}.000000 \PYGZhy{}0.064456    ...     \PYG{l+m}{0}.146201  \PYG{l+m}{0}.102173  \PYG{l+m}{0}.037533
RestBP   \PYG{l+m}{0}.284946 \PYGZhy{}0.064456  \PYG{l+m}{1}.000000    ...     \PYG{l+m}{0}.064762  \PYG{l+m}{0}.189171  \PYG{l+m}{0}.117382
Chol     \PYG{l+m}{0}.208950 \PYGZhy{}0.199915  \PYG{l+m}{0}.130120    ...     \PYG{l+m}{0}.061310  \PYG{l+m}{0}.046564 \PYGZhy{}0.004062
Fbs      \PYG{l+m}{0}.118530  \PYG{l+m}{0}.047862  \PYG{l+m}{0}.175340    ...     \PYG{l+m}{0}.025665  \PYG{l+m}{0}.005747  \PYG{l+m}{0}.059894
RestECG  \PYG{l+m}{0}.148868  \PYG{l+m}{0}.021647  \PYG{l+m}{0}.146560    ...     \PYG{l+m}{0}.084867  \PYG{l+m}{0}.114133  \PYG{l+m}{0}.133946
MaxHR   \PYGZhy{}0.393806 \PYGZhy{}0.048663 \PYGZhy{}0.045351    ...    \PYGZhy{}0.378103 \PYGZhy{}0.343085 \PYGZhy{}0.385601
ExAng    \PYG{l+m}{0}.091661  \PYG{l+m}{0}.146201  \PYG{l+m}{0}.064762    ...     \PYG{l+m}{1}.000000  \PYG{l+m}{0}.288223  \PYG{l+m}{0}.257748
Oldpeak  \PYG{l+m}{0}.203805  \PYG{l+m}{0}.102173  \PYG{l+m}{0}.189171    ...     \PYG{l+m}{0}.288223  \PYG{l+m}{1}.000000  \PYG{l+m}{0}.577537
Slope    \PYG{l+m}{0}.161770  \PYG{l+m}{0}.037533  \PYG{l+m}{0}.117382    ...     \PYG{l+m}{0}.257748  \PYG{l+m}{0}.577537  \PYG{l+m}{1}.000000

\PYG{o}{[}\PYG{l+m}{10} rows x \PYG{l+m}{10} columns\PYG{o}{]}\PYG{o}{)}

Process finished with \PYG{n+nb}{exit} code \PYG{l+m}{0}
\end{sphinxVerbatim}


\subsection{Audited results folder}
\label{\detokenize{demo:audited-results-folder}}\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_folder}.png}
\end{figure}
\end{quote}

The files in \sphinxcode{\sphinxupquote{00-audited\_results.xlsx}}:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Dataset\_summary

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_excel1}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{1}
\item {} 
Numeric\_summary

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_excel2}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{2}
\item {} 
Category\_summary

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_excel3}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{3}
\item {} 
Correlation\_matrix

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{t_excel4}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{4}
\item {} 
Histograms in \sphinxcode{\sphinxupquote{Histograms.pdf}}

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{hists}.png}
\end{figure}
\end{quote}
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\setcounter{enumi}{5}
\item {} 
Barplots in \sphinxcode{\sphinxupquote{Bar\_plots.pdf}}

\end{enumerate}
\begin{quote}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{bars}.png}
\end{figure}
\end{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
       .,,.
     ,\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;},
    .\PYGZhy{}\PYG{l+s+s1}{\PYGZsq{}{}`{}`;\PYGZhy{}\PYGZsq{}}\PYG{o}{)}\PYG{p}{;}\PYG{p}{;}.
   /\PYG{l+s+s1}{\PYGZsq{}  .\PYGZhy{}.  /*;;}
\PYG{l+s+s1}{ .\PYGZsq{}}    \PYG{l+s+se}{\PYGZbs{}d}    \PYG{l+s+se}{\PYGZbs{};}\PYG{p}{;}               .\PYG{p}{;}\PYG{p}{;}\PYG{p}{;},
/ o      \PYG{l+s+sb}{{}`}    \PYG{l+s+se}{\PYGZbs{};}    ,\PYGZus{}\PYGZus{}.     ,\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;},
\PYG{l+s+se}{\PYGZbs{}\PYGZus{}}\PYGZus{}, \PYGZus{}.\PYGZus{}\PYGZus{},\PYG{l+s+s1}{\PYGZsq{}   \PYGZbs{}\PYGZus{}.\PYGZhy{}\PYGZsq{}}\PYG{o}{)} \PYGZus{}\PYGZus{}\PYG{o}{)}\PYGZhy{}\PYGZhy{}.\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;},
 \PYG{l+s+sb}{{}`}\PYG{l+s+s2}{\PYGZdq{}\PYGZdq{}}\PYG{l+s+sb}{{}`}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{l+s+se}{\PYGZbs{} }      /\PYGZhy{}\PYG{l+s+s1}{\PYGZsq{})\PYGZus{}) \PYGZus{}\PYGZus{})  {}`\PYGZbs{}\PYGZsq{}} \PYG{l+s+s1}{\PYGZsq{};;;;;;}
\PYG{l+s+s1}{    ;*;;;        \PYGZhy{}\PYGZsq{}}\PYG{o}{)} \PYG{l+s+sb}{{}`}\PYG{o}{)}\PYGZus{}\PYG{o}{)}  \PYG{p}{\textbar{}}\PYG{l+s+se}{\PYGZbs{} }\PYG{p}{\textbar{}}  \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}
    \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{\textbar{}}        \PYG{l+s+sb}{{}`}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYG{l+s+sb}{{}`}    O \PYG{p}{\textbar{}} \PYG{p}{\textbar{}} \PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}
    *\PYG{p}{;}*\PYG{p}{;}\PYG{l+s+se}{\PYGZbs{}\textbar{}}                 O  / \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*
   \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}/\PYG{p}{\textbar{}}    .\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYG{l+s+se}{\PYGZbs{} }     / \PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}
  \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}*\PYG{p}{;}/ \PYG{l+s+se}{\PYGZbs{} }   \PYG{p}{\textbar{}}        \PYG{l+s+s1}{\PYGZsq{}.   ({}`. ;;;*;;;}
\PYG{l+s+s1}{  ;;;;;\PYGZsq{}}. \PYG{p}{;}   \PYG{p}{\textbar{}}          \PYG{o}{)}   \PYG{l+s+se}{\PYGZbs{} }\PYG{p}{\textbar{}} \PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}
  ,\PYG{p}{;}*\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}\PYG{l+s+se}{\PYGZbs{}/}   \PYG{p}{\textbar{}}.        /   /\PYG{l+s+sb}{{}`} \PYG{p}{\textbar{}} \PYG{l+s+s1}{\PYGZsq{};;;*;}
\PYG{l+s+s1}{   ;;;;;;/    \textbar{}/       /   /\PYGZus{}\PYGZus{}/   \PYGZsq{}}\PYG{p}{;}\PYG{p}{;}\PYG{p}{;}
   \PYG{l+s+s1}{\PYGZsq{}*wf*/     \textbar{}       /    \textbar{}      ;*;}
\PYG{l+s+s1}{        {}`\PYGZdq{}\PYGZdq{}\PYGZdq{}\PYGZdq{}{}`        {}`\PYGZdq{}\PYGZdq{}\PYGZdq{}\PYGZdq{}{}`     ;\PYGZsq{}}
\end{sphinxVerbatim}


\chapter{Main Reference}
\label{\detokenize{reference:main-reference}}\label{\detokenize{reference:reference}}\label{\detokenize{reference::doc}}
\begin{sphinxthebibliography}{PySparkA}
\bibitem[PyAudit]{reference:pyaudit}
Wenqiang Feng and Ming Chen. \sphinxhref{https://runawayhorse001.github.io/PyAudit/}{Python Data Audit Library API}, 2019.
\bibitem[PySparkAudit]{reference:pysparkaudit}
Wenqiang Feng and Ming Chen. \sphinxhref{https://runawayhorse001.github.io/PySparkAudit/}{PySpark Data Audit Library API}, 2019.
\end{sphinxthebibliography}



\renewcommand{\indexname}{Index}
\printindex
\end{document}